{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67ebddc-92f9-4079-9bdf-03c1723da7bb",
   "metadata": {},
   "source": [
    "based on main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059f0ad7-07ad-40dd-9b51-13932b20d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models import KGReasoning\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\n",
    "# from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from util import flatten_query, list2tuple, parse_time, set_global_seed, eval_tuple\n",
    "\n",
    "import collections\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c30dcc-67a9-4c6c-95f8-12ba228079fe",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810639e0-395c-425b-9061-c767d7af1772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }\n",
    "name_query_dict = {value: key for key, value in query_name_dict.items()}\n",
    "all_tasks = list(name_query_dict.keys()) # ['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', '2u-DM', 'up-DNF', 'up-DM']\n",
    "\n",
    "print(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bcf015-3999-443a-8b67-de3a03662b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyArgs:\n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "args = DummyArgs()\n",
    "args.cuda = True\n",
    "args.geo = \"beta\" # choices=['vec', 'box', 'beta']\n",
    "args.gamma = 12.0\n",
    "args.box_mode = \"(none,0.02)\" # Query2box\n",
    "args.beta_mode = \"(1600,2)\" # BetaE relational projection\n",
    "args.data_path = \"data/FB15k-237-betae\"\n",
    "args.batch_size = 64 #1024\n",
    "args.cpu_num = 1# 10\n",
    "args.negative_sample_size = 128\n",
    "args.hidden_dim = 500\n",
    "args.test_batch_size = 3 #2\n",
    "args.print_on_screen = True\n",
    "args.test_log_steps = 1000\n",
    "args.learning_rate = 0.0001\n",
    "args.max_steps = 100000\n",
    "args.evaluate_union = \"DNF\" # choices=['DNF', 'DM'] evaluate union querioes, disjunctive normal form (DNF) or de Morgan's laws (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de24b73d-f941-433b-b85c-646c87df325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pin'] ['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "# different query types\n",
    "tasks = all_tasks[10:11]\n",
    "\n",
    "if args.geo in ['box']:\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.box_mode)\n",
    "elif args.geo in ['vec']:\n",
    "    tmp_str = \"g-{}\".format(args.gamma)\n",
    "elif args.geo == 'beta':\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.beta_mode)\n",
    "\n",
    "print(tasks, all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925f09da-75e3-48a9-8aef-ce389cccac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/stats.txt' % args.data_path) as f:\n",
    "    entrel = f.readlines()\n",
    "    nentity = int(entrel[0].split(' ')[-1])\n",
    "    nrelation = int(entrel[1].split(' ')[-1])\n",
    "\n",
    "args.nentity = nentity\n",
    "args.nrelation = nrelation\n",
    "\n",
    "logging.info('-------------------------------'*3)\n",
    "logging.info('Geo: %s' % args.geo)\n",
    "logging.info('Data Path: %s' % args.data_path)\n",
    "logging.info('#entity: %d' % nentity)\n",
    "logging.info('#relation: %d' % nrelation)\n",
    "# logging.info('#max steps: %d' % args.max_steps)\n",
    "# logging.info('Evaluate unoins using: %s' % args.evaluate_union)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24a6e6-a9e3-4d88-8b9a-49b0bcb907de",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05285434-3f28-439c-9214-e835ecedf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args, tasks):\n",
    "    '''\n",
    "    Load queries and remove queries not in tasks\n",
    "    '''\n",
    "    logging.info(\"loading data\")\n",
    "    train_queries = pickle.load(open(os.path.join(args.data_path, \"train-queries.pkl\"), 'rb'))\n",
    "    train_answers = pickle.load(open(os.path.join(args.data_path, \"train-answers.pkl\"), 'rb'))\n",
    "    valid_queries = pickle.load(open(os.path.join(args.data_path, \"valid-queries.pkl\"), 'rb'))\n",
    "    valid_hard_answers = pickle.load(open(os.path.join(args.data_path, \"valid-hard-answers.pkl\"), 'rb'))\n",
    "    valid_easy_answers = pickle.load(open(os.path.join(args.data_path, \"valid-easy-answers.pkl\"), 'rb'))\n",
    "    test_queries = pickle.load(open(os.path.join(args.data_path, \"test-queries.pkl\"), 'rb'))\n",
    "    test_hard_answers = pickle.load(open(os.path.join(args.data_path, \"test-hard-answers.pkl\"), 'rb'))\n",
    "    test_easy_answers = pickle.load(open(os.path.join(args.data_path, \"test-easy-answers.pkl\"), 'rb'))\n",
    "    \n",
    "    # remove tasks not in args.tasks\n",
    "    for name in all_tasks:\n",
    "        if 'u' in name:\n",
    "            name, evaluate_union = name.split('-')\n",
    "        else:\n",
    "            evaluate_union = args.evaluate_union\n",
    "        if name not in tasks or evaluate_union != args.evaluate_union:\n",
    "            query_structure = name_query_dict[name if 'u' not in name else '-'.join([name, evaluate_union])]\n",
    "            if query_structure in train_queries:\n",
    "                del train_queries[query_structure]\n",
    "            if query_structure in valid_queries:\n",
    "                del valid_queries[query_structure]\n",
    "            if query_structure in test_queries:\n",
    "                del test_queries[query_structure]\n",
    "\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3d679e-4264-47ec-8530-9f8cc52b7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LOAD DATA\n",
    "based on tasks defined in args\n",
    "\"\"\"\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3c859-326a-44a7-9821-f48dda94e186",
   "metadata": {},
   "source": [
    "1. train_queries: for (e, r) given entityID and relationID, find all other entities that are connected to it.\n",
    "2. train_answers: given (e, r) this is the groundtruth answers of all entityIDs that are connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e36ea2b-54a6-49ff-8791-3a47cd98c06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(collections.defaultdict, 1),\n",
       " (collections.defaultdict, 1496890),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 97804),\n",
       " (collections.defaultdict, 97804)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(type(x), len(x)) for x in [train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0989196-e3d2-43b3-aa73-b622426225e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "((6099, (1, 97)), (32, (97, -2)))\n",
      "True\n",
      "valid_hard_answers {2137, 4834, 547, 605, 2213, 11847, 12722, 10098, 1332, 2418, 12246, 4377, 8892, 10269, 350}\n",
      "valid_easy_answers {6532, 9989, 2951, 7053, 9872, 10385, 10899, 1943, 12951, 6936, 4122, 9628, 12573, 6429, 7330, 7459, 7204, 7848, 11947, 10412, 6829, 7981, 9904, 10672, 10290, 13618, 14000, 4668, 11198, 1982, 1727, 3903, 9282, 3906, 13774, 8407, 6873, 346, 6112, 3172, 8805, 8939, 5355, 11374, 9457, 5876, 5493, 12791, 1656, 10105, 5630}\n",
      "**********\n",
      "((6099, (1, 97)), (32, (97, -2)))\n",
      "False\n",
      "train_answers {6532, 9989, 2951, 7053, 9872, 10385, 10899, 12951, 1943, 6936, 4122, 9628, 6429, 12573, 7330, 7459, 7204, 7848, 11947, 10412, 6829, 7981, 9904, 10672, 10290, 13618, 14000, 4668, 11198, 1982, 1727, 3903, 9282, 3906, 13774, 8407, 6873, 346, 6112, 3172, 8805, 8939, 5355, 11374, 9457, 5876, 5493, 12791, 1656, 10105, 5630}\n",
      "**********\n",
      "((6099, (1, 97)), (32, (97, -2)))\n",
      "False\n",
      "test_hard_answers set()\n",
      "test_easy_answers set()\n"
     ]
    }
   ],
   "source": [
    "queryType = (('e', ('r', 'r')), ('e', ('r', 'n')))\n",
    "\n",
    "ex_val_q = random.sample(valid_queries[queryType], 1)[0]\n",
    "print(\"*\" * 10)\n",
    "print(ex_val_q)\n",
    "print(ex_val_q in valid_queries[queryType])\n",
    "print(\"valid_hard_answers\", valid_hard_answers[ex_val_q])\n",
    "print(\"valid_easy_answers\", valid_easy_answers[ex_val_q])\n",
    "\n",
    "# get example query\n",
    "ex_q = ex_val_q #(6288, (8,))\n",
    "print(\"*\" * 10)\n",
    "print(ex_q)\n",
    "print(ex_q in train_queries[queryType])\n",
    "print(\"train_answers\", train_answers[ex_q])\n",
    "\n",
    "ex_test_q = ex_val_q\n",
    "print(\"*\" * 10)\n",
    "print(ex_test_q)\n",
    "print(ex_test_q in test_queries[queryType])\n",
    "print(\"test_hard_answers\", test_hard_answers[ex_val_q])\n",
    "print(\"test_easy_answers\", test_easy_answers[ex_val_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361141a3-9026-43e9-b95e-c20f65b11a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train_queries 14968\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAINING Data Preparation\n",
    "\"\"\"\n",
    "train_path_queries = defaultdict(set)\n",
    "for query_structure in train_queries:\n",
    "#     train_path_queries[query_structure] = set(random.sample(train_queries[query_structure], 1))\n",
    "    train_path_queries[query_structure] = train_queries[query_structure]\n",
    "            \n",
    "train_path_queries = flatten_query(train_path_queries)\n",
    "print(\"number of train_queries\", len(train_path_queries))\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "                            # {(e,r): (entityID, relID)} and {(e, r): [entityID]}\n",
    "                            TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=args.cpu_num,\n",
    "                            collate_fn=TrainDataset.collate_fn\n",
    "                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4f3a56-d4b9-4e3f-8610-42bd94e8c321",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error (('e', ('r', 'r')), ('e', ('r', 'n')))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VALIDATION Data Preparation\n",
    "\"\"\"\n",
    "# for each type of structure / key\n",
    "for query_structure in valid_queries:\n",
    "    try:\n",
    "        print(query_name_dict[query_structure[1]]+\": \"+str(len(valid_queries[query_structure])))\n",
    "    except:\n",
    "        print(\"error\", query_structure)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    TestDataset(\n",
    "        flatten_query(valid_queries), \n",
    "        args.nentity, \n",
    "        args.nrelation, \n",
    "    ), \n",
    "    batch_size=args.test_batch_size,\n",
    "    num_workers=args.cpu_num, \n",
    "    collate_fn=TestDataset.collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcc71dd-c692-4b5f-bcb2-4e15fbb8ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter gamma: torch.Size([1]), require_grad = False\n",
      "Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "Parameter entity_embedding: torch.Size([14505, 1000]), require_grad = True\n",
      "Parameter relation_embedding: torch.Size([474, 500]), require_grad = True\n",
      "Parameter center_net.layer1.weight: torch.Size([1000, 1000]), require_grad = True\n",
      "Parameter center_net.layer1.bias: torch.Size([1000]), require_grad = True\n",
      "Parameter center_net.layer2.weight: torch.Size([500, 1000]), require_grad = True\n",
      "Parameter center_net.layer2.bias: torch.Size([500]), require_grad = True\n",
      "Parameter projection_net.layer1.weight: torch.Size([1600, 1500]), require_grad = True\n",
      "Parameter projection_net.layer1.bias: torch.Size([1600]), require_grad = True\n",
      "Parameter projection_net.layer0.weight: torch.Size([1000, 1600]), require_grad = True\n",
      "Parameter projection_net.layer0.bias: torch.Size([1000]), require_grad = True\n",
      "Parameter projection_net.layer2.weight: torch.Size([1600, 1600]), require_grad = True\n",
      "Parameter projection_net.layer2.bias: torch.Size([1600]), require_grad = True\n",
      "Parameter Number: 22807700\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL DEFINITION\n",
    "\"\"\"\n",
    "model = KGReasoning(\n",
    "    nentity=nentity,\n",
    "    nrelation=nrelation,\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    gamma=args.gamma,\n",
    "    geo=args.geo,\n",
    "    use_cuda = args.cuda,\n",
    "    box_mode=eval_tuple(args.box_mode),\n",
    "    beta_mode = eval_tuple(args.beta_mode),\n",
    "    test_batch_size=args.test_batch_size,\n",
    "    query_name_dict = query_name_dict\n",
    ")\n",
    "\n",
    "logging.info('Model Parameter Configuration:')\n",
    "num_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "    if param.requires_grad:\n",
    "        num_params += np.prod(param.size())\n",
    "print('Parameter Number: %d' % num_params)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "current_learning_rate = args.learning_rate\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=current_learning_rate\n",
    ")\n",
    "warm_up_steps = args.max_steps // 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0855a87-dd99-4832-b2fb-3eb8519ab0bd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bfcdb2-a2c2-49fc-a329-f80a198a60c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343fe35f32b4c43af77a4b47b0755a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-195ec1d49a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# train model for a step over all batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_path_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtraining_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, optimizer, train_iterator, args, step)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mpositive_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mbatch_queries_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mbatch_idxs_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36mone_shot_iterator\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_shot_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAIN LOOP\n",
    "\"\"\"\n",
    "init_step = 0\n",
    "\n",
    "training_logs = []\n",
    "# loop over all batches\n",
    "# initialising train_path_iterator is expensive. So at certain loop it might take some time to load\n",
    "for step in tqdm(range(init_step, args.max_steps)):\n",
    "    # train model for a step over all batches\n",
    "    log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "    training_logs.append(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25b30b6e-05ce-4343-b36f-a8e6ca97332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(\n",
    "    {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    },\n",
    "    os.path.join(\"checkpoint\", \"model-beta-er.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2873f-ca65-406b-91c6-a9d1059a20c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c781f49-e149-4cd2-846b-6f7aca456631",
   "metadata": {},
   "source": [
    "## DEBUG TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d748f69-474b-47e9-ade8-07655dd285dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_sample_loss': 0.39944127202033997,\n",
       " 'negative_sample_loss': 1.0847606658935547,\n",
       " 'loss': 0.7421009540557861}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\n",
    "\n",
    "# model.train_step(model, optimizer, train_other_iterator, args, step)\n",
    "\n",
    "model, optimizer, train_iterator, args, step = model, optimizer, train_path_iterator, args, step\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# there's an overhead operation to shufflte the train_iterator that makes this expensive to run\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\n",
    "\n",
    "# group queries into batch\n",
    "batch_queries_dict = collections.defaultdict(list)\n",
    "batch_idxs_dict = collections.defaultdict(list)\n",
    "for i, query in enumerate(batch_queries): # group queries with same structure\n",
    "    batch_queries_dict[query_structures[i]].append(query)\n",
    "    batch_idxs_dict[query_structures[i]].append(i)\n",
    "\n",
    "for query_structure in batch_queries_dict:\n",
    "    if args.cuda:\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "    else:\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\n",
    "\n",
    "if args.cuda:\n",
    "    positive_sample = positive_sample.cuda()\n",
    "    negative_sample = negative_sample.cuda()\n",
    "    subsampling_weight = subsampling_weight.cuda()\n",
    "\n",
    "# score positive and negative samples\n",
    "positive_logit, negative_logit, subsampling_weight, _ = model(positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "\n",
    "# calculate loss\n",
    "# positive samples should have label of 1 while negative samples label of 0\n",
    "negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\n",
    "positive_score = F.logsigmoid(positive_logit).mean(dim=1)\n",
    "# aggregate loss with subsampling_weight\n",
    "positive_sample_loss = - (subsampling_weight * positive_score).sum()\n",
    "negative_sample_loss = - (subsampling_weight * negative_score).sum()\n",
    "positive_sample_loss /= subsampling_weight.sum()\n",
    "negative_sample_loss /= subsampling_weight.sum()\n",
    "loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "log = {\n",
    "    'positive_sample_loss': positive_sample_loss.item(),\n",
    "    'negative_sample_loss': negative_sample_loss.item(),\n",
    "    'loss': loss.item(),\n",
    "}\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be0565a-6810-4e7b-87cc-34a456006c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== input ===\n",
      "torch.Size([64]) torch.Size([64, 128]) 64 64 torch.Size([64])\n",
      "=== output ===\n",
      "torch.Size([64, 1]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== input ===\")\n",
    "print(positive_sample.shape, negative_sample.shape, len(batch_queries), len(query_structures), subsampling_weight.shape)\n",
    "print(\"=== output ===\")\n",
    "print(positive_logit.shape, negative_logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0021b4a-3f5e-45a4-8fb2-577fed266eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2061813a-7d68-4213-9c0f-e03a82497261",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd87bedf-3738-4190-a7d6-fe2148b4db3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "checkpoint = torch.load(os.path.join(\"checkpoint\", \"model-beta-er.pt\"))\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0330becc-417c-4054-b067-aae8b2c6cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step):\n",
    "    '''\n",
    "    Evaluate queries in dataloader\n",
    "    '''\n",
    "    average_metrics = defaultdict(float)\n",
    "    all_metrics = defaultdict(float)\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics:\n",
    "        log_metrics(mode+\" \"+query_name_dict[query_structure], step, metrics[query_structure])\n",
    "        for metric in metrics[query_structure]:\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != 'num_queries':\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "        num_queries += metrics[query_structure]['num_queries']\n",
    "        num_query_structures += 1\n",
    "\n",
    "    for metric in average_metrics:\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    log_metrics('%s average'%mode, step, average_metrics)\n",
    "\n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9becd1-6d16-4448-bc03-302d2c28bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(mode, step, metrics):\n",
    "    '''\n",
    "    Print the evaluation logs\n",
    "    '''\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e329dce-199c-4ece-b3fd-a6801dd6e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44921785-a04a-4497-881f-f7ce14045c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1667/1667 [02:33<00:00, 10.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'pin_MRR': 0.0007912687872187234,\n",
       "             'pin_HITS1': 2.38745866343379e-05,\n",
       "             'pin_HITS3': 0.00017614683248102665,\n",
       "             'pin_HITS10': 0.001281430758163333,\n",
       "             'pin_num_queries': 5000,\n",
       "             'average_MRR': 0.0007912687872187234,\n",
       "             'average_HITS1': 2.38745866343379e-05,\n",
       "             'average_HITS3': 0.00017614683248102665,\n",
       "             'average_HITS10': 0.001281430758163333})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"`\n",
    "EVAL\n",
    "\"\"\"\n",
    "step = -1\n",
    "valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict, 'Valid', step)\n",
    "valid_all_metrics\n",
    "\n",
    "# after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562e202-6d27-4191-aa22-5f294bc66016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9ace12-0564-4b65-bab9-43d42ffa01c8",
   "metadata": {},
   "source": [
    "## DEBUG TEST STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4ffd7b-d3e9-4af7-97f3-22e8504f32c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1667/1667 [02:34<00:00, 10.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function models.KGReasoning.test_step.<locals>.<lambda>()>,\n",
       "            {(('e', ('r', 'r')), ('e', ('r', 'n'))): defaultdict(int,\n",
       "                         {'MRR': 0.0007912687872187234,\n",
       "                          'HITS1': 2.38745866343379e-05,\n",
       "                          'HITS3': 0.00017614683248102665,\n",
       "                          'HITS10': 0.001281430758163333,\n",
       "                          'num_queries': 5000})})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def evaluate in main.py\"\"\"\n",
    "\n",
    "metrics = model.test_step(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c530c00-d2da-4e8f-b2b7-7a036e1639e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ace005a85e14ca0904a8db744d2bf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504]]),\n",
       " [[2250, 456, 63, 160, 29, -2],\n",
       "  [11233, 216, 69, 32, 57, -2],\n",
       "  [90, 333, 202, 3161, 202, -2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for negative_sample, queries, queries_unflatten, query_structures in tqdm(valid_dataloader, disable=not args.print_on_screen):\n",
    "    break\n",
    "    \n",
    "negative_sample, queries, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9d867-2cf2-4ef9-8bda-2e42a52292ec",
   "metadata": {},
   "source": [
    "1. why is there no positive_sample in test_dataloader\n",
    "2. how to embed query vector and perform projection & intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087e015d-4567-45a2-9e05-1ad756270268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a5ab94dd9d49fb90b03f2312954b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1667 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {(('e', ('r', 'r')), ('e', ('r', 'n'))): defaultdict(int,\n",
       "                         {'MRR': 0.0007912687872187234,\n",
       "                          'HITS1': 2.38745866343379e-05,\n",
       "                          'HITS3': 0.00017614683248102665,\n",
       "                          'HITS10': 0.001281430758163333,\n",
       "                          'num_queries': 5000})})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.test_step in models.py\"\"\"\n",
    "model, easy_answers, hard_answers, args, test_dataloader, query_name_dict = model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict\n",
    "\n",
    "model.eval()\n",
    "\n",
    "step = 0\n",
    "total_steps = len(test_dataloader)\n",
    "logs = collections.defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # process per batch\n",
    "    # loop through every validation dataset\n",
    "    # negative sample is basically all entities in nentity\n",
    "    for negative_sample, queries, queries_unflatten, query_structures in tqdm(test_dataloader, disable=not args.print_on_screen):\n",
    "        batch_queries_dict = collections.defaultdict(list)\n",
    "        batch_idxs_dict = collections.defaultdict(list)\n",
    "        \n",
    "        # for each test query\n",
    "        for i, query in enumerate(queries):\n",
    "            batch_queries_dict[query_structures[i]].append(query)\n",
    "            batch_idxs_dict[query_structures[i]].append(i)\n",
    "            \n",
    "        # convert each positive query to a LongTensor\n",
    "        for query_structure in batch_queries_dict:\n",
    "            if args.cuda:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "            else:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\n",
    "            \n",
    "        # convert each negative query to a LongTensor\n",
    "        if args.cuda:\n",
    "            negative_sample = negative_sample.cuda()\n",
    "            \n",
    "        # get prediction output\n",
    "        # (2, number_of_edges) same dimension with negative_sample\n",
    "        # this is basically embedding lookup\n",
    "        \"\"\"model.forward\"\"\"\n",
    "        # negative_sample here is just a list of all entities, some of them are actually positive\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "          \n",
    "        # ... scoring ...\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        # sort from maximum value based on logit values\n",
    "        argsort = torch.argsort(negative_logit, dim=1, descending=True)\n",
    "        ranking = argsort.clone().to(torch.float)\n",
    "        if len(argsort) == args.test_batch_size: # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "        else: # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args.cuda:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1).cuda()) # achieve the ranking of all entities\n",
    "            else:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1)) # achieve the ranking of all entities\n",
    "        \n",
    "        # loop through ranking\n",
    "        # score every query in the dataloader batch\n",
    "        for idx, (i, query, query_structure) in enumerate(zip(argsort[:, 0], queries_unflatten, query_structures)):\n",
    "            # get groundtruth labels\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = len(hard_answer)\n",
    "            num_easy = len(easy_answer)\n",
    "            assert len(hard_answer.intersection(easy_answer)) == 0\n",
    "\n",
    "            # compare ranking of groundtruth (easy_answer, hard_answer) and predicted results\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = torch.sort(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args.cuda:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float).cuda()\n",
    "            else:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float)\n",
    "            cur_ranking = cur_ranking - answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = torch.mean(1./cur_ranking).item()\n",
    "            h1 = torch.mean((cur_ranking <= 1).to(torch.float)).item()\n",
    "            h3 = torch.mean((cur_ranking <= 3).to(torch.float)).item()\n",
    "            h10 = torch.mean((cur_ranking <= 10).to(torch.float)).item()\n",
    "\n",
    "            logs[query_structure].append({\n",
    "                'MRR': mrr,\n",
    "                'HITS1': h1,\n",
    "                'HITS3': h3,\n",
    "                'HITS10': h10,\n",
    "                'num_hard_answer': num_hard,\n",
    "            })\n",
    "\n",
    "metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "for query_structure in logs:\n",
    "    for metric in logs[query_structure][0].keys():\n",
    "        if metric in ['num_hard_answer']:\n",
    "            continue\n",
    "        metrics[query_structure][metric] = sum([log[metric] for log in logs[query_structure]])/len(logs[query_structure])\n",
    "    metrics[query_structure]['num_queries'] = len(logs[query_structure])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e63ed-b7aa-4178-b330-1bebbd486db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c44708ce-8b20-4c84-b2d2-3725ce2298d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-5c039bc54806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mall_union_beta_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_query_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_queries_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquery_structure\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mall_idxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idxs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquery_structure\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mall_alpha_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36membed_query_beta\u001b[1;34m(self, queries, query_structure, idx)\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mbeta_embedding_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_query_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m                 \u001b[0malpha_embedding_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mbeta_embedding_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36membed_query_beta\u001b[1;34m(self, queries, query_structure, idx)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall_relation_flag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'e'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_regularizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m                 \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "\"\"\"model.forward\"\"\"\n",
    "# model.forward(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "\n",
    "# model.geo == \"beta\"\n",
    "\n",
    "# done per batch\n",
    "\"\"\"model.forward_beta\"\"\"\n",
    "# compared to vec, just add union of offset embeddings\n",
    "\n",
    "# model.forward_beta(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "# negative_sample is a list of entities to be scored as potential answers to the queries\n",
    "# batch_queries_dict stores list of queries (in this case (e, r) to be scored)\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict = None, negative_sample, None, batch_queries_dict, batch_idxs_dict\n",
    "\n",
    "all_idxs, all_alpha_embeddings, all_beta_embeddings = [], [], []\n",
    "all_union_idxs, all_union_alpha_embeddings, all_union_beta_embeddings = [], [], []\n",
    "for query_structure in batch_queries_dict:\n",
    "    if 'u' in model.query_name_dict[query_structure] and 'DNF' in model.query_name_dict[query_structure]:\n",
    "        # embedding \n",
    "        alpha_embedding, beta_embedding, _ = model.embed_query_beta(model.transform_union_query(batch_queries_dict[query_structure], \n",
    "                                                            query_structure), \n",
    "                                                        model.transform_union_structure(query_structure), 0)\n",
    "        all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "        all_union_alpha_embeddings.append(alpha_embedding)\n",
    "        all_union_beta_embeddings.append(beta_embedding)\n",
    "    else:\n",
    "        alpha_embedding, beta_embedding, _ = model.embed_query_beta(batch_queries_dict[query_structure], query_structure, 0)\n",
    "        all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "        all_alpha_embeddings.append(alpha_embedding)\n",
    "        all_beta_embeddings.append(beta_embedding)\n",
    "\n",
    "if len(all_alpha_embeddings) > 0:\n",
    "    all_alpha_embeddings = torch.cat(all_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "    all_beta_embeddings = torch.cat(all_beta_embeddings, dim=0).unsqueeze(1)\n",
    "    all_dists = torch.distributions.beta.Beta(all_alpha_embeddings, all_beta_embeddings)\n",
    "if len(all_union_alpha_embeddings) > 0:\n",
    "    all_union_alpha_embeddings = torch.cat(all_union_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_beta_embeddings = torch.cat(all_union_beta_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "    all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "    all_union_dists = torch.distributions.beta.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "\n",
    "if type(subsampling_weight) != type(None):\n",
    "    subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "\n",
    "# in test, positive samples are not given\n",
    "if type(positive_sample) != type(None):\n",
    "    if len(all_alpha_embeddings) > 0:\n",
    "        positive_sample_regular = positive_sample[all_idxs]\n",
    "        positive_embedding = torch.index_select(model.entity_embedding, dim=0, index=positive_sample_regular).unsqueeze(1)\n",
    "        positive_logit = model.cal_logit_beta(positive_embedding, all_dists)\n",
    "    else:\n",
    "        positive_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0:\n",
    "        positive_sample_union = positive_sample[all_union_idxs]\n",
    "        positive_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=positive_sample_union).unsqueeze(1).unsqueeze(1)\n",
    "        )\n",
    "        positive_union_logit = model.cal_logit_beta(positive_embedding, all_union_dists)\n",
    "        # take max over all\n",
    "        positive_union_logit = torch.max(positive_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        positive_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "        \n",
    "    # combine normal embeddings and union\n",
    "    positive_logit = torch.cat([positive_logit, positive_union_logit], dim=0)\n",
    "else:\n",
    "    positive_logit = None\n",
    "\n",
    "# in test, negative samples are basically all possible list of entities\n",
    "if type(negative_sample) != type(None):\n",
    "    if len(all_alpha_embeddings) > 0:\n",
    "        negative_sample_regular = negative_sample[all_idxs]\n",
    "        batch_size, negative_size = negative_sample_regular.shape\n",
    "        negative_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1)\n",
    "        )\n",
    "        negative_logit = model.cal_logit_beta(negative_embedding, all_dists)\n",
    "    else:\n",
    "        negative_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0:\n",
    "        negative_sample_union = negative_sample[all_union_idxs]\n",
    "        batch_size, negative_size = negative_sample_union.shape\n",
    "        negative_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=negative_sample_union.view(-1)).view(batch_size, 1, negative_size, -1)\n",
    "        )\n",
    "        negative_union_logit = model.cal_logit_beta(negative_embedding, all_union_dists)\n",
    "        negative_union_logit = torch.max(negative_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        negative_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "    negative_logit = torch.cat([negative_logit, negative_union_logit], dim=0)\n",
    "else:\n",
    "    negative_logit = None\n",
    "\n",
    "positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e307f54-7568-484d-bc6f-3e2933a432bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4cf7d8a-221f-4760-bf36-64f3f80db165",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.8093,  1.0532,  1.2320,  2.1677,  1.0971,  1.4936,  0.7001,  0.9773,\n",
       "           0.9894,  1.1520,  0.9649,  1.5259,  1.1835,  1.1495,  1.2265,  0.9741,\n",
       "           0.8203,  2.3615,  0.3846,  1.0021,  1.1155,  2.1380,  1.1384,  0.8335,\n",
       "           0.8611,  1.4863,  0.9719,  1.1760,  0.9690,  0.9143,  1.5212,  1.0361,\n",
       "           1.5558,  1.2096,  0.8359,  1.0983,  0.7586,  1.0377,  1.4682,  0.4126,\n",
       "           1.4653,  0.6982,  0.3125,  0.9255,  1.1584,  0.8919,  0.8637,  1.0260,\n",
       "           2.0751,  0.7999,  0.9885,  1.5400,  0.5941,  0.6524,  1.3403,  1.3706,\n",
       "           0.8378,  0.9711,  2.1258,  0.9225,  1.3712,  1.6246,  1.3157,  1.4441,\n",
       "           0.7829,  1.2202,  0.9627,  1.0495,  1.2817,  0.9193,  1.0477,  0.7604,\n",
       "           1.2056,  1.0763,  0.9099,  1.1671,  0.9200,  0.6366,  0.9358,  0.9655,\n",
       "           0.9517,  2.0458,  1.1489,  0.8780,  1.0216,  1.0172,  0.6254,  1.0263,\n",
       "           0.9308,  1.1204,  1.1252,  0.8459,  1.8095,  0.8713,  0.9986,  0.9017,\n",
       "           1.5004,  0.9206,  0.5568,  0.7580,  1.1452,  1.3401,  0.8728,  1.0302,\n",
       "           1.0455,  1.1160,  1.1382,  0.8181,  1.3922,  1.2404,  1.2522,  1.1441,\n",
       "           0.5055,  1.2132,  0.1369,  1.7863,  1.0758,  1.3955,  4.2565,  0.9791,\n",
       "           0.5902,  2.2383,  1.2541,  0.8030,  0.8314,  0.9546,  2.1032,  2.0861,\n",
       "           1.0529,  1.2114,  0.8429,  2.1067,  0.9661,  1.0976,  1.2114,  1.1550,\n",
       "           4.3479,  1.0131,  1.0866,  1.2789,  0.8153,  0.5134,  1.0409,  1.0596,\n",
       "           2.2216,  1.2054,  0.8370,  0.7906,  0.5888, 15.6777,  1.0605,  0.5706,\n",
       "           1.2731,  1.8401,  1.0042,  0.7701,  2.4303,  1.5944,  1.0087,  0.9839,\n",
       "           0.9390,  0.9755,  0.6672,  1.2523,  1.0583, 14.7013,  1.0811,  0.7634,\n",
       "           0.8627,  0.9196,  0.6464,  0.8220,  1.3780,  1.1872,  1.0956,  0.9777,\n",
       "           0.8965,  1.0453,  0.8422,  0.5481,  1.1632,  0.9410,  1.7072,  0.7947,\n",
       "           1.0896,  1.0856,  1.0007,  0.7547,  0.9325,  1.0569,  1.0966,  1.1367,\n",
       "           0.9921,  0.6604,  1.1973,  0.9374,  0.9675,  1.7154,  0.8465,  1.4081,\n",
       "           1.1801,  0.8995,  1.2472,  0.8987,  1.0408,  1.0489,  1.2451,  0.8478,\n",
       "           1.0558,  0.7299,  1.0708,  1.3521,  1.0030,  0.9997,  2.6440,  1.0009,\n",
       "           1.8858,  0.9456,  1.0736,  0.7791,  1.0873,  1.4388,  0.9938,  1.0063,\n",
       "           0.8729,  0.8365,  0.9578,  0.9895,  1.3875,  1.0793,  1.0143,  0.6390,\n",
       "           0.9015,  1.2229,  0.7557,  1.1015,  0.9767,  1.2565,  1.1574,  1.4515,\n",
       "           1.1216,  2.4878,  1.6338,  1.1439,  1.0609,  0.4917,  0.9624,  1.0464,\n",
       "           0.7787,  1.3893,  1.0468,  0.6483,  1.0052,  0.5208,  1.1905,  1.1047,\n",
       "           0.9189,  1.0145,  1.0111,  1.0574,  0.9559,  1.0811,  0.9689,  0.9724,\n",
       "           0.9492,  1.7025,  1.0060,  0.8817,  0.9951,  1.0823,  1.7948,  1.1767,\n",
       "           0.9351,  1.0676,  1.1248,  1.0447,  1.0472,  1.0180, 10.6595,  1.5931,\n",
       "           0.4877,  1.0250,  0.8548,  1.0762,  2.8499,  4.3768,  1.2802,  1.0726,\n",
       "           1.5385,  0.8926,  1.0904,  1.3822,  1.0417,  0.9214,  1.2751,  3.6670,\n",
       "           2.5712,  1.3498,  1.5418,  0.7309,  1.2004,  0.6988,  1.5685,  0.9902,\n",
       "           2.4495,  1.1498,  0.6799,  1.2895,  0.8926,  0.5312,  1.0505,  0.8359,\n",
       "           1.4195,  2.0970,  1.4056,  0.9587,  0.9221,  1.0573,  1.3833,  0.9806,\n",
       "           1.6734,  0.9387,  1.0029,  1.0692,  1.0716, 14.2836,  1.1311,  1.0036,\n",
       "           1.6402,  1.0638,  0.5280,  0.8356,  1.0199,  1.2325,  1.3515,  0.7272,\n",
       "           1.0543,  1.5415,  0.9435,  1.7769,  1.1684,  0.9803,  1.2093,  1.4759,\n",
       "           0.9134, 15.0506,  0.9917,  1.3089,  0.8853,  0.7227,  0.8820,  1.0851,\n",
       "           0.9197,  0.8678,  0.8478,  1.1336,  0.9631,  1.0998,  0.9283,  1.0233,\n",
       "           1.1448,  1.1656,  1.4034, 14.5370,  1.7048,  1.0831,  0.9073,  1.0979,\n",
       "           1.9988,  0.9815,  1.2192,  1.1494,  0.8623,  1.6146,  1.2824,  1.1170,\n",
       "           0.6174,  0.8795,  2.7530,  1.9416,  4.6317,  1.6729,  0.8473,  0.5301,\n",
       "           1.0156,  1.1264,  1.6535,  1.1674,  1.0368,  0.9466,  1.4281,  1.1766,\n",
       "           1.0379,  0.8780,  1.1074,  1.0251,  0.9774,  1.7410,  1.0837,  1.0450,\n",
       "           0.9365,  1.3040,  0.6907,  1.4217,  0.9534,  1.6099,  1.3728,  1.6231,\n",
       "           1.0072,  0.7116,  1.1844,  1.1405,  1.0940,  1.0647,  2.0588,  0.8359,\n",
       "           0.8731,  0.6290,  1.1007,  0.8950,  1.1847,  1.5015,  1.3570,  1.4527,\n",
       "           0.9614,  1.0189,  0.8995,  0.8770,  1.8340,  1.5266,  0.8072,  0.9998,\n",
       "           1.7364,  1.1469,  1.1698,  1.3196,  1.9787,  1.1463,  1.0263,  1.3910,\n",
       "           0.7840,  0.8670,  1.6234,  1.4392,  0.8716,  0.9501,  1.1443,  1.0520,\n",
       "           0.8863,  0.2680,  0.9456,  0.8833,  1.0910,  0.9916,  1.3004,  0.9719,\n",
       "           1.0892,  1.3824,  1.1106,  0.9397,  0.9628,  1.0294,  1.0762,  0.9327,\n",
       "           1.0607,  1.0393,  0.8512,  1.0616,  1.3689,  0.8133,  0.2892,  1.4386,\n",
       "           1.3275,  0.8160,  1.1053,  1.2455,  0.9819,  0.9839,  1.1476,  3.9939,\n",
       "           0.9213,  7.8441,  0.6719,  1.4411,  0.8977,  0.4999,  0.9242,  1.6896,\n",
       "           0.8413,  0.9194,  2.1247,  1.5751,  0.3589,  0.8485,  0.8059,  0.9445,\n",
       "           0.8401,  1.6707,  0.9130,  1.1211],\n",
       "         [ 5.7375,  1.0646,  1.2086,  2.1618,  1.1095,  1.4857,  0.7005,  0.9852,\n",
       "           0.9410,  1.1507,  0.9751,  1.4633,  1.1674,  1.1174,  1.2196,  0.9734,\n",
       "           0.8196,  2.3279,  0.3742,  1.0005,  1.0965,  2.1286,  1.1478,  0.8199,\n",
       "           0.8523,  1.4969,  0.9816,  1.1892,  0.9969,  0.9909,  1.5372,  1.0337,\n",
       "           1.5544,  1.2231,  0.8296,  1.1047,  0.7642,  1.0415,  1.4822,  0.4026,\n",
       "           1.4840,  0.6924,  0.3390,  0.9346,  1.1164,  0.9055,  0.8745,  1.0133,\n",
       "           1.9574,  0.8054,  0.9686,  1.5140,  0.6009,  0.6561,  1.3369,  1.3431,\n",
       "           0.8253,  0.9724,  2.1096,  0.9330,  1.4417,  1.6942,  1.3225,  1.5136,\n",
       "           0.7698,  1.2160,  0.9753,  1.0318,  1.2795,  0.9209,  1.0598,  0.7504,\n",
       "           1.2138,  1.0832,  0.9098,  1.1565,  0.9323,  0.6298,  0.9445,  1.0155,\n",
       "           0.9438,  1.9446,  1.1317,  0.8931,  1.0120,  1.0455,  0.7863,  1.0364,\n",
       "           0.9318,  1.1032,  1.1262,  0.8536,  1.7603,  0.8926,  1.0015,  0.9257,\n",
       "           1.5079,  0.9299,  0.5625,  0.7604,  1.1759,  1.2366,  0.8674,  1.0263,\n",
       "           1.0420,  1.1178,  1.1264,  0.8264,  1.3765,  1.2432,  1.2482,  1.1586,\n",
       "           0.7437,  1.2294,  0.1456,  1.7479,  1.0644,  1.4409,  4.3821,  0.9851,\n",
       "           0.5919,  2.0305,  1.2444,  0.8220,  0.7692,  0.9650,  2.1229,  2.0831,\n",
       "           1.0476,  1.2675,  0.8329,  2.1044,  0.9647,  1.0865,  1.2155,  1.1554,\n",
       "           4.1770,  1.0197,  1.0928,  1.2590,  0.8479,  0.5330,  1.0421,  1.0614,\n",
       "           2.2088,  1.2194,  0.8407,  0.7970,  0.5877, 16.1429,  1.0539,  0.5637,\n",
       "           1.2781,  1.9055,  1.0166,  0.7652,  2.5966,  1.5886,  1.0176,  0.9770,\n",
       "           0.9528,  0.9515,  0.6434,  1.2349,  1.0656, 14.3936,  1.0622,  0.7611,\n",
       "           0.8809,  0.9384,  0.6489,  0.8095,  1.4664,  1.1629,  1.1022,  0.9728,\n",
       "           0.9185,  1.0288,  0.8242,  0.5533,  1.0869,  0.9406,  1.6856,  0.7749,\n",
       "           1.0901,  1.0934,  0.9846,  0.7616,  0.9369,  1.0358,  1.1404,  1.1420,\n",
       "           0.9868,  0.6661,  1.1913,  0.9786,  0.9902,  1.6661,  0.8533,  1.3565,\n",
       "           1.1748,  0.9049,  1.2646,  0.8874,  1.0258,  1.0009,  1.2401,  0.8359,\n",
       "           1.0843,  0.7101,  1.0680,  1.3733,  0.9964,  1.0021,  2.6402,  1.0064,\n",
       "           1.9006,  0.9412,  1.0743,  0.7702,  1.0990,  1.4391,  0.9849,  1.0212,\n",
       "           0.8613,  0.8259,  0.9617,  0.9924,  1.3984,  1.1345,  1.0147,  0.6351,\n",
       "           0.8979,  1.2184,  0.7618,  1.0916,  0.9692,  1.2551,  1.1582,  1.4478,\n",
       "           1.0831,  2.5924,  1.6390,  1.1339,  1.0521,  0.5050,  0.9559,  1.0712,\n",
       "           0.7982,  1.3560,  1.0461,  0.6544,  1.0226,  0.4791,  1.2593,  1.1721,\n",
       "           0.9132,  1.0342,  1.0229,  1.0526,  0.9571,  1.0465,  0.9735,  0.9723,\n",
       "           0.9459,  1.6854,  1.0155,  0.8680,  0.9884,  1.0671,  1.8091,  1.1672,\n",
       "           0.9198,  1.0593,  1.1122,  1.0514,  1.0652,  1.0018, 11.2762,  1.5948,\n",
       "           0.5307,  1.0270,  0.8513,  1.0696,  2.6388,  4.3838,  1.2648,  1.0396,\n",
       "           1.5380,  0.9107,  1.1030,  1.3770,  1.0315,  0.9182,  1.2701,  3.5749,\n",
       "           2.4440,  1.3362,  1.6775,  0.7383,  1.1996,  0.7201,  1.5639,  0.9841,\n",
       "           2.5079,  1.1532,  0.6689,  1.2543,  0.8967,  0.5178,  1.1112,  0.8321,\n",
       "           1.4095,  2.1070,  1.4652,  0.9597,  0.9572,  1.0444,  1.3737,  0.9442,\n",
       "           1.7144,  0.9489,  0.9316,  1.0621,  1.0609, 13.6084,  1.1176,  1.0245,\n",
       "           1.6072,  1.0638,  0.5158,  0.8456,  1.0177,  1.2379,  1.3453,  0.7167,\n",
       "           1.0601,  1.5355,  0.9344,  1.9106,  1.1538,  0.9744,  1.1988,  1.4414,\n",
       "           0.9093, 14.9450,  0.9746,  1.2490,  0.9024,  0.7255,  0.8895,  1.0859,\n",
       "           0.9160,  0.8822,  0.8446,  1.1322,  0.9772,  1.1252,  0.9225,  1.0418,\n",
       "           1.1434,  1.1659,  1.4389, 14.2918,  1.7087,  1.0831,  0.9444,  1.1427,\n",
       "           1.9867,  0.9693,  1.2141,  1.1529,  0.8694,  1.6562,  1.2591,  1.1212,\n",
       "           0.6267,  0.8737,  2.5923,  1.7052,  4.4743,  1.6204,  0.8489,  0.5232,\n",
       "           1.0132,  1.1388,  1.6678,  1.1620,  1.0690,  0.9520,  1.4527,  1.1724,\n",
       "           1.0112,  0.8852,  1.1157,  1.0506,  0.9949,  1.7171,  1.0806,  1.0305,\n",
       "           0.8883,  1.2906,  0.6950,  1.4160,  0.9766,  1.5683,  1.3749,  1.3642,\n",
       "           1.0058,  0.7105,  1.1940,  1.1423,  1.1587,  1.1079,  2.0754,  0.8125,\n",
       "           0.8786,  0.6397,  1.1004,  0.8687,  1.1789,  1.5109,  1.3432,  1.4539,\n",
       "           0.9539,  1.1536,  0.9137,  0.8750,  1.8413,  1.5138,  0.8352,  1.0005,\n",
       "           1.9165,  1.1585,  1.2079,  1.3112,  1.9864,  1.1626,  1.0184,  1.3751,\n",
       "           0.7787,  0.8698,  1.6230,  1.6328,  0.8572,  0.9513,  1.1408,  1.0530,\n",
       "           0.8900,  0.2648,  0.9543,  0.8739,  1.0925,  0.9838,  1.3349,  1.0743,\n",
       "           1.0942,  1.3808,  1.0999,  1.0753,  0.9674,  1.0441,  1.0636,  0.9240,\n",
       "           1.0759,  1.0161,  0.8486,  1.0558,  1.4021,  0.8052,  0.2865,  1.4199,\n",
       "           1.3246,  0.8169,  1.1338,  1.2180,  1.0010,  0.9630,  1.1828,  3.9064,\n",
       "           0.9425,  7.1838,  0.6206,  1.4392,  0.8940,  0.5164,  0.9288,  1.6892,\n",
       "           0.8651,  0.9262,  1.9912,  1.5305,  0.3564,  0.8453,  0.8194,  0.9235,\n",
       "           0.8424,  1.7038,  0.9122,  1.1110]], device='cuda:0',\n",
       "        grad_fn=<SumBackward1>),\n",
       " tensor([[ 0.9145,  0.9932,  0.9727,  0.9158,  0.9885,  0.7810,  0.8764,  1.4279,\n",
       "           0.7560,  0.9320,  0.9228,  0.8179,  1.1595,  1.1584,  0.6456,  0.9794,\n",
       "           0.7627,  0.7927,  0.7810,  1.1340,  0.9173,  0.8965,  1.2754,  0.9446,\n",
       "           1.1121,  1.2149,  0.9001,  0.9933,  1.1582,  1.0339,  0.8833,  1.6613,\n",
       "           1.0398,  0.7072,  0.6400,  0.9819,  3.0428,  1.4150,  0.7696,  1.6228,\n",
       "           0.9024,  0.8467,  1.0100,  3.1113,  1.0937,  0.9346,  2.1444,  1.1211,\n",
       "           0.9136,  1.0556,  1.3994,  0.8539,  0.5947,  1.3452,  1.2852,  1.0873,\n",
       "           1.7014,  2.9578,  1.1994,  0.6150,  1.1946,  1.2207,  1.1150,  1.0251,\n",
       "           1.0898,  1.2384,  1.1295,  1.3715,  1.0735,  0.9823,  0.9307,  0.5252,\n",
       "           1.0731,  1.0056,  0.8798,  1.9938,  1.7246,  1.1849,  0.9609,  1.1612,\n",
       "           1.1765,  8.6224,  0.9825,  0.5643,  1.1467,  1.1911,  0.7498,  1.2217,\n",
       "           0.9283,  0.9340,  1.3845,  2.0998,  0.6846,  0.5091,  1.0121,  1.3112,\n",
       "           1.2619,  1.1743,  0.9368,  2.1571,  1.1941,  1.0098,  0.8176,  0.9858,\n",
       "           1.1063,  1.1958,  0.9278,  0.8823,  0.6887,  1.1859,  1.1687,  9.5430,\n",
       "           1.4322,  1.0141,  1.0034,  0.8373,  0.9449,  1.1168,  0.8413,  1.0210,\n",
       "           0.8332,  1.3940,  0.9495,  1.0857,  0.9868,  1.0070,  0.7734,  1.0843,\n",
       "           0.9151,  0.9403,  0.9249,  0.6606,  0.9444,  0.9380,  1.1523,  1.0911,\n",
       "           0.9137,  1.1657,  0.9773,  1.1063,  1.2041,  0.5123,  1.0671,  1.2125,\n",
       "           0.8827,  1.6121,  0.8440,  0.6588,  0.9404,  1.0311,  0.6386,  1.1746,\n",
       "           0.8547,  0.8695,  0.9215,  1.3698,  1.2903,  1.1221,  1.2826,  0.9981,\n",
       "           1.0126,  1.0303,  0.7858,  5.5155,  1.1492,  0.9495,  1.0790,  1.0878,\n",
       "           1.1840,  1.0626,  0.3331,  1.3692,  1.2894,  1.2260,  1.0831,  0.9672,\n",
       "           0.6858,  1.2868,  1.8114,  0.6389,  5.5144,  0.9424,  1.3344,  1.3993,\n",
       "           1.0931,  0.1126,  1.5530,  0.7627,  1.1445,  1.0024,  1.0544,  0.8179,\n",
       "           1.0716,  0.3978,  2.3024,  0.7858,  1.0334,  2.0738,  0.7044,  0.9495,\n",
       "           1.2158,  0.8320,  1.0730,  0.8388,  0.9485,  1.0874,  1.6482,  6.8322,\n",
       "           1.6620,  1.4125,  1.3258,  1.1995,  0.9937,  1.0256,  0.9109,  0.5596,\n",
       "           0.8444,  1.1955,  0.8974,  0.9125,  0.7205,  1.4496,  0.9467,  3.1124,\n",
       "           1.1537,  3.1061,  1.0822,  1.0408,  1.2334,  1.0542,  0.6475,  2.0599,\n",
       "           1.4163,  1.4996,  0.9319,  1.0636,  0.9874,  1.6731,  1.5934,  1.2150,\n",
       "           0.8604,  1.1298,  2.0844,  1.4004,  0.9626,  0.7602,  1.2923,  0.8405,\n",
       "           6.0160,  1.3521,  1.0305,  0.6177,  1.3229,  0.8739,  1.1602,  1.3145,\n",
       "           1.3233,  1.0338,  1.4685,  0.8114,  1.8080,  0.9981,  0.9133,  0.9634,\n",
       "           0.8353,  0.6822,  1.0554,  1.0753,  0.9952,  1.4862,  1.8840,  0.8656,\n",
       "           1.6321,  1.4924,  0.9880,  0.9906,  1.0858,  1.0344,  1.0437,  2.0929,\n",
       "           1.6229,  1.0369,  1.4617,  0.7522,  1.0016,  0.9185,  1.0175,  0.7803,\n",
       "           1.3965,  1.3072,  1.0045,  0.9621,  0.8273,  1.3107,  1.0998,  2.0000,\n",
       "           9.2704,  0.7744,  1.2114,  1.4575,  0.6866,  0.7674,  0.8485,  0.9897,\n",
       "           1.1214,  1.0669,  1.9813, 18.6406,  1.0696,  1.1413,  0.8648,  0.9207,\n",
       "           0.6215,  0.4875,  1.1533,  0.9115,  1.0159,  1.7532,  0.8584,  1.1370,\n",
       "           1.2497,  0.8151,  0.7872,  1.3453,  1.1888,  1.5019,  0.9546,  1.0129,\n",
       "           1.1434,  1.0473,  0.6974,  1.1402,  1.9425,  1.4642,  1.2323,  1.0749,\n",
       "           1.2175,  1.2525,  0.7980,  1.0146,  1.6155,  1.4171,  0.8053,  1.0897,\n",
       "           0.7760,  0.9137,  0.8989,  1.2330,  0.8849,  0.6408,  1.2656,  0.5428,\n",
       "          14.9247,  0.7196,  0.9493,  1.1818,  0.8154,  1.2405,  1.2196,  1.0193,\n",
       "           0.9645,  0.7578,  1.1241,  1.2570,  1.7913,  1.0169,  1.0892,  0.9275,\n",
       "           0.7072,  1.0289,  1.5008,  1.2096,  2.7521,  1.5371,  1.0878,  0.4828,\n",
       "           1.4095,  4.7271,  1.2634,  1.1654,  1.9987,  0.8611,  1.0389,  0.7044,\n",
       "           0.9070,  1.0996,  0.9252,  1.2672,  1.0725,  0.8797,  1.0417,  1.5006,\n",
       "           1.1613,  0.8921,  1.1432,  1.1793,  0.8756,  0.7328,  1.3780,  0.8694,\n",
       "           0.9601,  1.3231,  0.6091,  0.9859,  1.1352,  0.9425,  1.5822,  0.9894,\n",
       "           1.0274,  0.7845,  0.8092,  1.0818,  1.6400,  1.0331,  1.0255,  1.0437,\n",
       "           1.0354,  1.1092,  1.1485,  1.1126,  0.8546,  1.1757,  1.0854,  1.6049,\n",
       "           1.0181,  1.1624,  0.7847,  0.2216,  0.4639,  1.3889,  1.0276,  1.0017,\n",
       "           0.6722,  0.3089,  0.9333,  1.0799,  0.8307,  0.9548,  0.7990,  1.2079,\n",
       "           0.8915,  1.2680,  0.9724,  1.5287,  1.7380,  1.2439,  1.3760,  0.9546,\n",
       "           1.0527,  0.1498,  2.1915,  0.8014,  0.8173,  1.0009,  1.0027,  1.1012,\n",
       "           1.4795,  1.0023,  1.0083,  0.9290,  0.8842,  1.0436,  0.6839,  0.6703,\n",
       "           0.9711,  1.2981,  0.8145,  1.0909,  1.6091,  0.7425,  1.9672,  1.0524,\n",
       "           1.6866,  1.3177,  1.1177,  1.3996,  0.7722,  1.0635,  1.3247,  1.0385,\n",
       "           0.9295,  1.0577,  1.0186,  1.4816,  1.4134,  0.5407,  1.0695,  1.2839,\n",
       "           3.9097,  0.9526,  0.9647,  1.3141,  1.3170,  0.9349,  0.7952,  1.2315,\n",
       "           1.0925,  1.3311,  1.1927,  0.9895],\n",
       "         [ 0.9117,  0.9889,  0.9630,  0.9023,  0.9758,  0.7842,  0.8775,  1.3697,\n",
       "           0.7325,  0.9391,  0.9184,  0.8276,  1.1602,  1.1423,  0.6452,  0.9754,\n",
       "           0.7764,  0.8082,  0.7875,  1.1256,  0.9178,  0.9046,  1.3108,  0.9603,\n",
       "           1.1129,  1.2388,  0.9058,  0.9756,  1.1809,  1.0019,  0.8899,  1.6098,\n",
       "           1.0344,  0.6866,  0.6370,  0.9935,  2.8826,  1.3798,  0.7755,  1.6070,\n",
       "           0.8971,  0.8429,  1.0139,  2.9001,  1.1411,  0.9464,  2.1074,  1.1150,\n",
       "           0.9442,  1.0567,  1.4023,  0.8620,  0.6020,  1.3489,  1.2811,  1.0748,\n",
       "           1.7004,  2.7146,  1.2158,  0.6094,  1.2194,  1.2457,  1.1028,  1.0180,\n",
       "           1.1010,  1.2339,  1.1095,  1.3434,  1.0734,  0.9838,  0.9271,  0.5265,\n",
       "           1.0568,  0.9963,  0.9068,  1.9894,  1.7095,  1.1998,  1.1398,  1.1374,\n",
       "           1.1713,  8.2903,  0.9862,  0.6281,  1.1593,  1.1879,  0.8509,  1.2622,\n",
       "           0.9312,  0.9262,  1.4041,  2.1274,  0.6759,  0.5956,  1.0224,  1.2818,\n",
       "           1.2739,  1.1557,  0.9305,  2.2358,  1.2009,  1.0298,  0.8180,  0.9929,\n",
       "           1.1321,  1.2131,  0.9088,  0.8824,  0.7514,  1.1843,  1.1651,  9.7776,\n",
       "           1.4326,  1.0225,  1.0052,  0.8490,  0.9750,  1.1298,  0.8274,  1.0258,\n",
       "           0.8189,  1.3294,  0.9532,  1.0808,  0.9826,  1.0038,  0.7601,  1.0985,\n",
       "           0.9274,  0.9175,  0.9212,  0.6615,  0.8600,  0.9418,  1.1610,  1.0920,\n",
       "           0.9227,  1.1707,  0.9809,  1.0794,  1.1970,  0.5266,  1.0716,  1.2169,\n",
       "           0.8770,  1.6310,  0.8298,  0.6827,  0.9477,  1.0375,  0.6443,  1.1754,\n",
       "           0.8601,  0.8714,  0.9224,  1.3570,  1.3048,  1.1205,  1.3150,  1.0000,\n",
       "           1.0095,  1.0383,  0.7714,  5.8093,  1.1376,  0.9225,  1.0896,  1.0882,\n",
       "           1.1906,  1.0649,  0.3197,  1.3471,  1.2495,  1.2047,  1.1020,  0.9561,\n",
       "           0.6832,  1.2675,  1.7983,  0.6414,  5.5752,  0.9318,  1.3378,  1.4109,\n",
       "           1.0980,  0.1222,  1.5758,  0.7695,  1.1391,  0.9945,  1.0530,  0.8351,\n",
       "           1.0592,  0.4124,  2.4389,  0.7667,  1.1249,  2.1397,  0.7516,  0.9638,\n",
       "           1.1974,  0.8349,  1.0822,  0.8557,  0.9686,  1.1644,  1.6538,  6.4215,\n",
       "           1.7136,  1.4308,  1.3657,  1.2137,  0.9843,  1.0262,  0.8803,  0.5631,\n",
       "           0.8446,  1.2805,  0.8732,  0.9102,  0.7410,  1.4541,  0.9516,  3.6504,\n",
       "           1.1673,  3.3787,  1.0847,  1.0405,  1.2428,  1.0626,  0.6415,  2.0686,\n",
       "           1.3966,  1.4717,  0.9403,  1.0762,  1.0001,  1.6666,  1.6085,  1.1975,\n",
       "           0.8663,  1.1461,  2.0739,  1.4422,  0.9626,  0.7475,  1.3593,  0.8300,\n",
       "           6.3152,  1.3209,  1.0680,  0.6219,  1.2666,  0.8767,  1.2105,  1.2674,\n",
       "           1.2833,  0.9759,  1.4636,  0.7985,  1.7376,  1.0001,  0.9087,  0.9701,\n",
       "           0.8406,  0.6737,  1.0499,  1.0821,  0.9869,  1.5150,  1.8622,  0.8685,\n",
       "           1.6285,  1.4863,  0.9903,  0.9862,  1.0738,  1.0623,  1.0523,  2.1009,\n",
       "           1.5827,  1.0464,  1.4629,  0.7653,  0.9972,  0.9115,  1.0062,  0.7772,\n",
       "           1.3819,  1.2694,  1.0083,  0.9661,  0.8163,  1.3174,  1.1034,  1.8659,\n",
       "           8.4132,  0.7778,  1.2892,  1.4451,  0.6809,  0.7846,  0.8390,  0.9761,\n",
       "           1.1357,  1.0709,  1.8984, 18.6475,  1.0716,  1.1439,  0.9265,  0.9084,\n",
       "           0.6108,  0.4805,  1.1485,  0.9178,  1.1079,  1.7309,  0.8546,  1.1283,\n",
       "           1.2596,  0.8312,  0.7713,  1.3890,  1.1925,  1.4354,  0.9715,  0.9892,\n",
       "           1.1410,  1.0203,  0.6966,  1.1116,  1.8897,  1.4319,  1.2331,  1.0723,\n",
       "           1.2064,  1.2486,  0.8033,  0.9143,  1.5841,  1.4198,  0.8460,  1.0961,\n",
       "           0.7849,  0.9081,  0.9664,  1.2154,  0.8946,  0.6519,  1.2465,  0.5376,\n",
       "          14.9341,  0.7570,  0.9821,  1.1965,  0.8420,  1.2159,  1.2217,  1.0516,\n",
       "           0.9653,  0.6605,  1.1303,  1.2287,  1.7979,  1.0126,  1.0530,  0.8901,\n",
       "           0.7038,  1.0242,  1.4940,  1.2007,  2.6450,  1.5822,  1.0700,  0.4699,\n",
       "           1.4170,  5.1095,  1.2529,  1.1663,  2.0154,  0.8516,  1.0105,  0.6900,\n",
       "           0.9053,  1.0943,  0.9219,  1.2817,  1.0969,  0.8830,  1.0518,  1.5158,\n",
       "           1.1360,  0.9072,  1.1651,  1.1044,  0.9389,  0.7525,  1.3978,  0.8581,\n",
       "           0.9469,  1.3152,  0.6113,  0.9968,  1.1005,  0.9603,  1.5904,  0.9694,\n",
       "           1.0508,  0.7543,  0.8093,  1.0749,  1.5448,  1.0802,  1.0324,  1.0548,\n",
       "           1.0082,  1.0979,  1.1329,  1.1139,  0.8520,  1.1706,  1.0893,  1.5931,\n",
       "           1.0255,  1.2460,  0.8049,  0.2266,  0.4661,  1.3825,  1.0291,  1.0258,\n",
       "           0.6785,  0.3072,  0.9381,  1.0895,  0.8163,  0.9629,  0.7754,  1.2295,\n",
       "           0.8833,  1.3158,  1.0063,  1.6315,  1.7580,  1.2198,  1.3653,  0.9420,\n",
       "           1.0504,  0.1560,  2.0986,  0.8095,  0.8149,  1.0035,  1.0063,  1.1082,\n",
       "           1.4664,  0.9934,  1.0149,  0.9376,  0.8820,  1.0512,  0.6940,  0.6625,\n",
       "           0.9728,  1.3275,  0.8152,  1.0834,  1.6199,  0.7465,  1.9627,  1.0428,\n",
       "           1.6825,  1.2872,  1.1043,  1.4210,  0.7750,  1.1330,  1.3183,  1.0258,\n",
       "           0.9533,  1.0434,  1.0197,  1.4987,  1.4042,  0.5419,  1.0744,  1.2647,\n",
       "           3.9340,  0.9583,  0.9480,  1.3347,  1.3274,  0.9466,  0.8033,  1.2912,\n",
       "           1.0931,  1.3381,  1.1797,  0.9712]], device='cuda:0',\n",
       "        grad_fn=<SumBackward1>),\n",
       " 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.embed_query_beta in models.py\"\"\"\n",
    "# get the query embedding\n",
    "# input is (batch_size, query_type_length=2), query_structure=(e, r)\n",
    "# model.embed_query_beta(batch_queries_dict[query_structure], query_structure, 0)\n",
    "\n",
    "queries, query_structure, idx = batch_queries_dict[query_structure], query_structure, 0\n",
    "\n",
    "all_relation_flag = True\n",
    "for ele in query_structure[-1]:\n",
    "    print(ele)\n",
    "    # check that this is not a simple (..., r)\n",
    "    if ele not in ['r', 'n']:\n",
    "        # if there are double relations then all_relation_flag is True\n",
    "        all_relation_flag = False\n",
    "        break\n",
    "        \n",
    "# check that the second tuple is also relation or negation only (r, n)\n",
    "if all_relation_flag:\n",
    "    # first part\n",
    "    # if first part is anchor\n",
    "    if query_structure[0] == \"e\":\n",
    "        # get entity embedding\n",
    "        embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=queries[:, idx])\n",
    "        )\n",
    "        idx += 1\n",
    "    # if first part is a tuple, call the function again i.e. recursion\n",
    "    else:\n",
    "        # recursion\n",
    "        alpha_embedding, beta_embedding, idx = model.embed_query_beta(queries, query_structure[0], idx)\n",
    "\n",
    "    # second part\n",
    "    for i in range(len(query_structure[-1])):\n",
    "        # if any of the second part is negation, inverse the embedding\n",
    "        if query_structure[-1][i] == \"n\":\n",
    "            assert (queries[:, idx] == -2).all()\n",
    "            embedding = 1./embedding\n",
    "        # else get the relation embedding\n",
    "        else:\n",
    "            # get relation embedding\n",
    "            r_embedding = torch.index_select(model.relation_embedding, dim=0, index=queries[:, idx])\n",
    "            # add entity and relation embedding\n",
    "            embedding = model.projection_net(embedding, r_embedding)\n",
    "        idx += 1\n",
    "    alpha_embedding, beta_embedding = torch.chunk(embedding, 2, dim=-1)\n",
    "else:\n",
    "    alpha_embedding_list = []\n",
    "    beta_embedding_list = []\n",
    "    # for each query_structure\n",
    "    # find \n",
    "    for i in range(len(query_structure)):\n",
    "        alpha_embedding, beta_embedding, idx = model.embed_query_beta(queries, query_structure[i], idx)\n",
    "        alpha_embedding_list.append(alpha_embedding)\n",
    "        beta_embedding_list.append(beta_embedding)\n",
    "    alpha_embedding, beta_embedding = model.center_net(torch.stack(alpha_embedding_list), torch.stack(beta_embedding_list))\n",
    "    \n",
    "alpha_embedding, beta_embedding, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ceda26d5-1364-4dcc-81dc-326539c0caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 500 1600 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-27b4c6381dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_queries_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquery_structure\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m embedding = model.entity_regularizer(\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m ).to(\"cpu\")\n\u001b[0;32m     42\u001b[0m \u001b[0mr_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelation_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# define model.projection_net in model.embed_query_beta\n",
    "# embedding = model.projection_net(embedding, r_embedding)\n",
    "\n",
    "# model.projection_net\n",
    "print(model.projection_net.entity_dim, model.projection_net.relation_dim, model.projection_net.hidden_dim, model.projection_net.num_layers)\n",
    "\n",
    "class BetaProjection(nn.Module):\n",
    "    def __init__(self, entity_dim, relation_dim, hidden_dim, projection_regularizer, num_layers):\n",
    "        super(BetaProjection, self).__init__()\n",
    "        self.entity_dim = entity_dim\n",
    "        self.relation_dim = relation_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.layer1 = nn.Linear(self.entity_dim + self.relation_dim, self.hidden_dim)\n",
    "        self.layer0 = nn.Linear(self.hidden_dim, self.entity_dim)\n",
    "        \n",
    "        for nl in range(2, num_layers + 1):\n",
    "            setattr(self, \"layer{}\".format(nl), nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        for nl in range(num_layers + 1):\n",
    "            nn.init.xavier_uniform_(getattr(self, \"layer{}\".format(nl)).weight)\n",
    "        \n",
    "        self.projection_regularizer = projection_regularizer\n",
    "        \n",
    "    def forward(self, e_embedding, r_embedding):\n",
    "        print(\"e_embedding.shape, r_embedding.shape | \", e_embedding.shape, r_embedding.shape)\n",
    "        x = torch.cat([e_embedding, r_embedding], dim=-1)\n",
    "        print(\"x.shape | \", x.shape)\n",
    "        for nl in range(1, self.num_layers+1):\n",
    "            x = F.relu(getattr(self, \"layer{}\".format(nl))(x))\n",
    "        x = self.layer0(x)\n",
    "        x = self.projection_regularizer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "proj_model = BetaProjection(entity_dim=1000, relation_dim=500, hidden_dim=1600, \n",
    "                            projection_regularizer=model.projection_regularizer, num_layers=2).to(\"cpu\")\n",
    "\n",
    "queries, query_structure, idx = batch_queries_dict[query_structure], query_structure, 0\n",
    "embedding = model.entity_regularizer(\n",
    "    torch.index_select(model.entity_embedding, dim=0, index=queries[:, idx])\n",
    ").to(\"cpu\")\n",
    "r_embedding = torch.index_select(model.relation_embedding, dim=0, index=queries[:, idx]).to(\"cpu\")\n",
    "\n",
    "\n",
    "proj_model(embedding, r_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985c70f-338c-4be8-a3ec-405dc2c6b72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba5015-b6ba-4727-9af0-13c72f9544d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d7943b9-1b04-4430-894f-d694246d6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_embeddings.shape, beta_embeddings.shape | torch.Size([2, 2, 500]) torch.Size([2, 2, 500])\n",
      "all_embeddings.shape |  torch.Size([2, 2, 1000])\n",
      "layer1_act.shape |  torch.Size([2, 2, 1000])\n",
      "attention.shape |  torch.Size([2, 2, 500])\n",
      "alpha_embedding.shape |  torch.Size([2, 500])\n",
      "beta_embedding.shape |  torch.Size([2, 500])\n"
     ]
    }
   ],
   "source": [
    "## define model.center_net in model.embed_query_beta\n",
    "import torch.nn as nn\n",
    "\n",
    "class BetaIntersection(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(BetaIntersection, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.layer1 = nn.Linear(2 * self.dim, 2 * self.dim)\n",
    "        self.layer2 = nn.Linear(2 * self.dim, self.dim)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        nn.init.xavier_uniform_(self.layer2.weight)\n",
    "    \n",
    "    def forward(self, alpha_embeddings, beta_embeddings):\n",
    "        print(\"alpha_embeddings.shape, beta_embeddings.shape |\", alpha_embeddings.shape, beta_embeddings.shape)\n",
    "        \n",
    "        # input: [(batch_size, no_query_couple, feat_dim), (batch_size, no_query_couple, feat_dim)]\n",
    "        # output: (batch_size, no_query_couple, 2*feat_dim)\n",
    "        all_embeddings = torch.cat([alpha_embeddings, beta_embeddings], dim=-1)\n",
    "        print(\"all_embeddings.shape | \", all_embeddings.shape)\n",
    "        # (batch_size, no_query_couple, 2*feat_dim)\n",
    "        layer1_act = F.relu(self.layer1(all_embeddings))\n",
    "        print(\"layer1_act.shape | \", layer1_act.shape)\n",
    "        # (batch_size, no_query_couple, feat_dim)\n",
    "        attention = F.softmax(self.layer2(layer1_act), dim=0)\n",
    "        print(\"attention.shape | \", attention.shape)\n",
    "\n",
    "        # (batch_size, feat_dim)\n",
    "        alpha_embedding = torch.sum(attention * alpha_embeddings, dim=0)\n",
    "        print(\"alpha_embedding.shape | \", alpha_embedding.shape)\n",
    "        # (batch_size, feat_dim)\n",
    "        beta_embedding = torch.sum(attention * beta_embeddings, dim=0)\n",
    "        print(\"beta_embedding.shape | \", beta_embedding.shape)\n",
    "        \n",
    "        return alpha_embedding, beta_embedding\n",
    "    \n",
    "idx = 0\n",
    "alpha_embedding_list = []\n",
    "beta_embedding_list = []\n",
    "# for each query_structure\n",
    "# find \n",
    "for i in range(len(query_structure)):\n",
    "    alpha_embedding, beta_embedding, idx = model.embed_query_beta(queries, query_structure[i], idx)\n",
    "    alpha_embedding_list.append(alpha_embedding)\n",
    "    beta_embedding_list.append(beta_embedding)\n",
    "\n",
    "alpha_embedding, beta_embedding = model.center_net(torch.stack(alpha_embedding_list), torch.stack(beta_embedding_list))\n",
    "\n",
    "emb_model = BetaIntersection(dim = 500).to(\"cuda\")\n",
    "_, _ = emb_model(torch.stack(alpha_embedding_list), torch.stack(beta_embedding_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883d726-fc13-45da-ab3c-b4be25f68822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model.cal_logit_beta \"\"\"\n",
    "model.cal_logit_beta(negative_embedding, all_dists)\n",
    "\n",
    "# score / calculate distance between candidate embedding and query embedding\n",
    "# negative \n",
    "print(negative_embedding.shape, all_dists)\n",
    "\n",
    "entity_embedding, query_dist = negative_embedding, all_dists\n",
    "\n",
    "alpha_embedding, beta_embedding = torch.chunk(entity_embedding, 2, dim=-1)\n",
    "entity_dist = torch.distributions.beta.Beta(alpha_embedding, beta_embedding)\n",
    "logit = model.gamma - torch.norm(torch.distributions.kl.kl_divergence(entity_dist, query_dist), p=1, dim=-1)\n",
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98ec62-b9ef-4f56-82bd-3442c40df165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3edad-b6c0-4eb0-a172-60e0246945cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
