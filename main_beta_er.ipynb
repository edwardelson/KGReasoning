{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be4496f",
   "metadata": {},
   "source": [
    "based on main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd4b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "\r\n",
    "import argparse\r\n",
    "import json\r\n",
    "import logging\r\n",
    "import os\r\n",
    "import random\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from models import KGReasoning\r\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\r\n",
    "# from tensorboardX import SummaryWriter\r\n",
    "import time\r\n",
    "import pickle\r\n",
    "from collections import defaultdict\r\n",
    "from tqdm import tqdm\r\n",
    "from util import flatten_query, list2tuple, parse_time, set_global_seed, eval_tuple\r\n",
    "\r\n",
    "import collections\r\n",
    "import random\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b82906",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bae795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "query_name_dict = {('e',('r',)): '1p', \r\n",
    "                    ('e', ('r', 'r')): '2p',\r\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\r\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\r\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\r\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\r\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\r\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\r\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\r\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\r\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\r\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\r\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\r\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\r\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\r\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\r\n",
    "                }\r\n",
    "name_query_dict = {value: key for key, value in query_name_dict.items()}\r\n",
    "all_tasks = list(name_query_dict.keys()) # ['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', '2u-DM', 'up-DNF', 'up-DM']\r\n",
    "\r\n",
    "print(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d23530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyArgs:\r\n",
    "    def __init__(self):\r\n",
    "        None\r\n",
    "        \r\n",
    "args = DummyArgs()\r\n",
    "args.cuda = True\r\n",
    "args.geo = \"beta\" # choices=['vec', 'box', 'beta']\r\n",
    "args.gamma = 12.0\r\n",
    "args.box_mode = \"(none,0.02)\" # Query2box\r\n",
    "args.beta_mode = \"(1600,2)\" # BetaE relational projection\r\n",
    "args.data_path = \"data/FB15k-237-betae\"\r\n",
    "args.batch_size = 64 #1024\r\n",
    "args.cpu_num = 1# 10\r\n",
    "args.negative_sample_size = 128\r\n",
    "args.hidden_dim = 500\r\n",
    "args.test_batch_size = 3 #2\r\n",
    "args.print_on_screen = True\r\n",
    "args.test_log_steps = 1000\r\n",
    "args.learning_rate = 0.0001\r\n",
    "args.max_steps = 100000\r\n",
    "args.evaluate_union = \"DNF\" # choices=['DNF', 'DM'] evaluate union querioes, disjunctive normal form (DNF) or de Morgan's laws (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287f5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "# different query types\r\n",
    "tasks = all_tasks[0:1]\r\n",
    "\r\n",
    "if args.geo in ['box']:\r\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.box_mode)\r\n",
    "elif args.geo in ['vec']:\r\n",
    "    tmp_str = \"g-{}\".format(args.gamma)\r\n",
    "elif args.geo == 'beta':\r\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.beta_mode)\r\n",
    "\r\n",
    "print(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c147c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/stats.txt' % args.data_path) as f:\r\n",
    "    entrel = f.readlines()\r\n",
    "    nentity = int(entrel[0].split(' ')[-1])\r\n",
    "    nrelation = int(entrel[1].split(' ')[-1])\r\n",
    "\r\n",
    "args.nentity = nentity\r\n",
    "args.nrelation = nrelation\r\n",
    "\r\n",
    "logging.info('-------------------------------'*3)\r\n",
    "logging.info('Geo: %s' % args.geo)\r\n",
    "logging.info('Data Path: %s' % args.data_path)\r\n",
    "logging.info('#entity: %d' % nentity)\r\n",
    "logging.info('#relation: %d' % nrelation)\r\n",
    "# logging.info('#max steps: %d' % args.max_steps)\r\n",
    "# logging.info('Evaluate unoins using: %s' % args.evaluate_union)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402feab8",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args, tasks):\r\n",
    "    '''\r\n",
    "    Load queries and remove queries not in tasks\r\n",
    "    '''\r\n",
    "    logging.info(\"loading data\")\r\n",
    "    train_queries = pickle.load(open(os.path.join(args.data_path, \"train-queries.pkl\"), 'rb'))\r\n",
    "    train_answers = pickle.load(open(os.path.join(args.data_path, \"train-answers.pkl\"), 'rb'))\r\n",
    "    valid_queries = pickle.load(open(os.path.join(args.data_path, \"valid-queries.pkl\"), 'rb'))\r\n",
    "    valid_hard_answers = pickle.load(open(os.path.join(args.data_path, \"valid-hard-answers.pkl\"), 'rb'))\r\n",
    "    valid_easy_answers = pickle.load(open(os.path.join(args.data_path, \"valid-easy-answers.pkl\"), 'rb'))\r\n",
    "    test_queries = pickle.load(open(os.path.join(args.data_path, \"test-queries.pkl\"), 'rb'))\r\n",
    "    test_hard_answers = pickle.load(open(os.path.join(args.data_path, \"test-hard-answers.pkl\"), 'rb'))\r\n",
    "    test_easy_answers = pickle.load(open(os.path.join(args.data_path, \"test-easy-answers.pkl\"), 'rb'))\r\n",
    "    \r\n",
    "    # remove tasks not in args.tasks\r\n",
    "    for name in all_tasks:\r\n",
    "        if 'u' in name:\r\n",
    "            name, evaluate_union = name.split('-')\r\n",
    "        else:\r\n",
    "            evaluate_union = args.evaluate_union\r\n",
    "        if name not in tasks or evaluate_union != args.evaluate_union:\r\n",
    "            query_structure = name_query_dict[name if 'u' not in name else '-'.join([name, evaluate_union])]\r\n",
    "            if query_structure in train_queries:\r\n",
    "                del train_queries[query_structure]\r\n",
    "            if query_structure in valid_queries:\r\n",
    "                del valid_queries[query_structure]\r\n",
    "            if query_structure in test_queries:\r\n",
    "                del test_queries[query_structure]\r\n",
    "\r\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394139bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\r\n",
    "LOAD DATA\r\n",
    "based on tasks defined in args\r\n",
    "\"\"\"\r\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff18e6",
   "metadata": {},
   "source": [
    "1. train_queries: for (e, r) given entityID and relationID, find all other entities that are connected to it.\n",
    "2. train_answers: given (e, r) this is the groundtruth answers of all entityIDs that are connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9e1b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(collections.defaultdict, 1),\n",
       " (collections.defaultdict, 1496890),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 97804),\n",
       " (collections.defaultdict, 97804)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(type(x), len(x)) for x in [train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8c4607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "(6288, (8,))\n",
      "False\n",
      "valid_hard_answers set()\n",
      "valid_easy_answers set()\n",
      "**********\n",
      "(6288, (8,))\n",
      "True\n",
      "train_answers {9, 11, 117, 399}\n",
      "**********\n",
      "(6288, (8,))\n",
      "False\n",
      "test_hard_answers set()\n",
      "test_easy_answers set()\n"
     ]
    }
   ],
   "source": [
    "ex_val_q = (6288, (8,))\r\n",
    "print(\"*\" * 10)\r\n",
    "print(ex_val_q)\r\n",
    "print(ex_val_q in valid_queries[('e', ('r', ))])\r\n",
    "print(\"valid_hard_answers\", valid_hard_answers[ex_val_q])\r\n",
    "print(\"valid_easy_answers\", valid_easy_answers[ex_val_q])\r\n",
    "\r\n",
    "# get example query\r\n",
    "ex_q = ex_val_q #(6288, (8,))\r\n",
    "print(\"*\" * 10)\r\n",
    "print(ex_q)\r\n",
    "print(ex_q in train_queries[('e', ('r', ))])\r\n",
    "print(\"train_answers\", train_answers[ex_q])\r\n",
    "\r\n",
    "ex_test_q = ex_val_q\r\n",
    "print(\"*\" * 10)\r\n",
    "print(ex_test_q)\r\n",
    "print(ex_test_q in test_queries[('e', ('r', ))])\r\n",
    "print(\"test_hard_answers\", test_hard_answers[ex_val_q])\r\n",
    "print(\"test_easy_answers\", test_easy_answers[ex_val_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d21b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train_queries 149689\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "TRAINING Data Preparation\r\n",
    "\"\"\"\r\n",
    "train_path_queries = defaultdict(set)\r\n",
    "for query_structure in train_queries:\r\n",
    "#     train_path_queries[query_structure] = set(random.sample(train_queries[query_structure], 1))\r\n",
    "    train_path_queries[query_structure] = train_queries[query_structure]\r\n",
    "            \r\n",
    "train_path_queries = flatten_query(train_path_queries)\r\n",
    "print(\"number of train_queries\", len(train_path_queries))\r\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\r\n",
    "                            # {(e,r): (entityID, relID)} and {(e, r): [entityID]}\r\n",
    "                            TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\r\n",
    "                            batch_size=args.batch_size,\r\n",
    "                            shuffle=True,\r\n",
    "                            num_workers=args.cpu_num,\r\n",
    "                            collate_fn=TrainDataset.collate_fn\r\n",
    "                        ))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd27ffa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error ('e', ('r',))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "VALIDATION Data Preparation\r\n",
    "\"\"\"\r\n",
    "# for each type of structure / key\r\n",
    "for query_structure in valid_queries:\r\n",
    "    try:\r\n",
    "        print(query_name_dict[query_structure[1]]+\": \"+str(len(valid_queries[query_structure])))\r\n",
    "    except:\r\n",
    "        print(\"error\", query_structure)\r\n",
    "\r\n",
    "valid_dataloader = DataLoader(\r\n",
    "    TestDataset(\r\n",
    "        flatten_query(valid_queries), \r\n",
    "        args.nentity, \r\n",
    "        args.nrelation, \r\n",
    "    ), \r\n",
    "    batch_size=args.test_batch_size,\r\n",
    "    num_workers=args.cpu_num, \r\n",
    "    collate_fn=TestDataset.collate_fn\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9001b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter gamma: torch.Size([1]), require_grad = False\n",
      "Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "Parameter entity_embedding: torch.Size([14505, 1000]), require_grad = True\n",
      "Parameter relation_embedding: torch.Size([474, 500]), require_grad = True\n",
      "Parameter center_net.layer1.weight: torch.Size([1000, 1000]), require_grad = True\n",
      "Parameter center_net.layer1.bias: torch.Size([1000]), require_grad = True\n",
      "Parameter center_net.layer2.weight: torch.Size([500, 1000]), require_grad = True\n",
      "Parameter center_net.layer2.bias: torch.Size([500]), require_grad = True\n",
      "Parameter projection_net.layer1.weight: torch.Size([1600, 1500]), require_grad = True\n",
      "Parameter projection_net.layer1.bias: torch.Size([1600]), require_grad = True\n",
      "Parameter projection_net.layer0.weight: torch.Size([1000, 1600]), require_grad = True\n",
      "Parameter projection_net.layer0.bias: torch.Size([1000]), require_grad = True\n",
      "Parameter projection_net.layer2.weight: torch.Size([1600, 1600]), require_grad = True\n",
      "Parameter projection_net.layer2.bias: torch.Size([1600]), require_grad = True\n",
      "Parameter Number: 22807700\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "MODEL DEFINITION\r\n",
    "\"\"\"\r\n",
    "model = KGReasoning(\r\n",
    "    nentity=nentity,\r\n",
    "    nrelation=nrelation,\r\n",
    "    hidden_dim=args.hidden_dim,\r\n",
    "    gamma=args.gamma,\r\n",
    "    geo=args.geo,\r\n",
    "    use_cuda = args.cuda,\r\n",
    "    box_mode=eval_tuple(args.box_mode),\r\n",
    "    beta_mode = eval_tuple(args.beta_mode),\r\n",
    "    test_batch_size=args.test_batch_size,\r\n",
    "    query_name_dict = query_name_dict\r\n",
    ")\r\n",
    "\r\n",
    "logging.info('Model Parameter Configuration:')\r\n",
    "num_params = 0\r\n",
    "for name, param in model.named_parameters():\r\n",
    "    print('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\r\n",
    "    if param.requires_grad:\r\n",
    "        num_params += np.prod(param.size())\r\n",
    "print('Parameter Number: %d' % num_params)\r\n",
    "\r\n",
    "model = model.cuda()\r\n",
    "\r\n",
    "current_learning_rate = args.learning_rate\r\n",
    "optimizer = torch.optim.Adam(\r\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \r\n",
    "    lr=current_learning_rate\r\n",
    ")\r\n",
    "warm_up_steps = args.max_steps // 2\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3a5a9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fae9df1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343fe35f32b4c43af77a4b47b0755a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-195ec1d49a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# train model for a step over all batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_path_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtraining_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, optimizer, train_iterator, args, step)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mpositive_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mbatch_queries_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mbatch_idxs_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36mone_shot_iterator\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_shot_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "TRAIN LOOP\r\n",
    "\"\"\"\r\n",
    "init_step = 0\r\n",
    "\r\n",
    "training_logs = []\r\n",
    "# loop over all batches\r\n",
    "# initialising train_path_iterator is expensive. So at certain loop it might take some time to load\r\n",
    "for step in tqdm(range(init_step, args.max_steps)):\r\n",
    "    # train model for a step over all batches\r\n",
    "    log = model.train_step(model, optimizer, train_path_iterator, args, step)\r\n",
    "    training_logs.append(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7518f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\r\n",
    "torch.save(\r\n",
    "    {\r\n",
    "        'model_state_dict': model.state_dict(),\r\n",
    "        'optimizer_state_dict': optimizer.state_dict()\r\n",
    "    },\r\n",
    "    os.path.join(\"checkpoint\", \"model-beta-er.pt\")\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412e1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b779a0",
   "metadata": {},
   "source": [
    "## DEBUG TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34f87451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_sample_loss': 0.39944127202033997,\n",
       " 'negative_sample_loss': 1.0847606658935547,\n",
       " 'loss': 0.7421009540557861}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\r\n",
    "\r\n",
    "# model.train_step(model, optimizer, train_other_iterator, args, step)\r\n",
    "\r\n",
    "model, optimizer, train_iterator, args, step = model, optimizer, train_path_iterator, args, step\r\n",
    "\r\n",
    "model.train()\r\n",
    "optimizer.zero_grad()\r\n",
    "\r\n",
    "# there's an overhead operation to shufflte the train_iterator that makes this expensive to run\r\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\r\n",
    "\r\n",
    "# group queries into batch\r\n",
    "batch_queries_dict = collections.defaultdict(list)\r\n",
    "batch_idxs_dict = collections.defaultdict(list)\r\n",
    "for i, query in enumerate(batch_queries): # group queries with same structure\r\n",
    "    batch_queries_dict[query_structures[i]].append(query)\r\n",
    "    batch_idxs_dict[query_structures[i]].append(i)\r\n",
    "\r\n",
    "for query_structure in batch_queries_dict:\r\n",
    "    if args.cuda:\r\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\r\n",
    "    else:\r\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\r\n",
    "\r\n",
    "if args.cuda:\r\n",
    "    positive_sample = positive_sample.cuda()\r\n",
    "    negative_sample = negative_sample.cuda()\r\n",
    "    subsampling_weight = subsampling_weight.cuda()\r\n",
    "\r\n",
    "# score positive and negative samples\r\n",
    "positive_logit, negative_logit, subsampling_weight, _ = model(positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\r\n",
    "\r\n",
    "# calculate loss\r\n",
    "# positive samples should have label of 1 while negative samples label of 0\r\n",
    "negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\r\n",
    "positive_score = F.logsigmoid(positive_logit).mean(dim=1)\r\n",
    "# aggregate loss with subsampling_weight\r\n",
    "positive_sample_loss = - (subsampling_weight * positive_score).sum()\r\n",
    "negative_sample_loss = - (subsampling_weight * negative_score).sum()\r\n",
    "positive_sample_loss /= subsampling_weight.sum()\r\n",
    "negative_sample_loss /= subsampling_weight.sum()\r\n",
    "loss = (positive_sample_loss + negative_sample_loss)/2\r\n",
    "\r\n",
    "loss.backward()\r\n",
    "optimizer.step()\r\n",
    "\r\n",
    "log = {\r\n",
    "    'positive_sample_loss': positive_sample_loss.item(),\r\n",
    "    'negative_sample_loss': negative_sample_loss.item(),\r\n",
    "    'loss': loss.item(),\r\n",
    "}\r\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af028596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== input ===\n",
      "torch.Size([64]) torch.Size([64, 128]) 64 64 torch.Size([64])\n",
      "=== output ===\n",
      "torch.Size([64, 1]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== input ===\")\r\n",
    "print(positive_sample.shape, negative_sample.shape, len(batch_queries), len(query_structures), subsampling_weight.shape)\r\n",
    "print(\"=== output ===\")\r\n",
    "print(positive_logit.shape, negative_logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c6a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9fb93bd",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3232906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\r\n",
    "checkpoint = torch.load(os.path.join(\"checkpoint\", \"model-beta-er.pt\"))\r\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05e332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step):\r\n",
    "    '''\r\n",
    "    Evaluate queries in dataloader\r\n",
    "    '''\r\n",
    "    average_metrics = defaultdict(float)\r\n",
    "    all_metrics = defaultdict(float)\r\n",
    "\r\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\r\n",
    "    num_query_structures = 0\r\n",
    "    num_queries = 0\r\n",
    "    for query_structure in metrics:\r\n",
    "        log_metrics(mode+\" \"+query_name_dict[query_structure], step, metrics[query_structure])\r\n",
    "        for metric in metrics[query_structure]:\r\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\r\n",
    "            if metric != 'num_queries':\r\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\r\n",
    "        num_queries += metrics[query_structure]['num_queries']\r\n",
    "        num_query_structures += 1\r\n",
    "\r\n",
    "    for metric in average_metrics:\r\n",
    "        average_metrics[metric] /= num_query_structures\r\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\r\n",
    "    log_metrics('%s average'%mode, step, average_metrics)\r\n",
    "\r\n",
    "    return all_metrics\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58ac962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(mode, step, metrics):\n",
    "    '''\n",
    "    Print the evaluation logs\n",
    "    '''\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00f1fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5d8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6698/6698 [10:03<00:00, 11.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'1p_MRR': 0.0008123985262628899,\n",
       "             '1p_HITS1': 8.294350321439768e-07,\n",
       "             '1p_HITS3': 7.2575563690407755e-06,\n",
       "             '1p_HITS10': 0.0015338022258891695,\n",
       "             '1p_num_queries': 20094,\n",
       "             'average_MRR': 0.0008123985262628899,\n",
       "             'average_HITS1': 8.294350321439768e-07,\n",
       "             'average_HITS3': 7.2575563690407755e-06,\n",
       "             'average_HITS10': 0.0015338022258891695})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"`\n",
    "EVAL\n",
    "\"\"\"\n",
    "step = -1\n",
    "valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict, 'Valid', step)\n",
    "valid_all_metrics\n",
    "\n",
    "# after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009f1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c841b40f",
   "metadata": {},
   "source": [
    "## DEBUG TEST STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7636d583",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 41/6698 [00:05<15:38,  7.10it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ca31d8149208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"def evaluate in main.py\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_easy_answers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_hard_answers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_name_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mtest_step\u001b[1;34m(model, easy_answers, hard_answers, args, test_dataloader, query_name_dict, save_result, save_str, save_empty)\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mqueries_unflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mqueries_unflatten\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mquery_structures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mquery_structures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m                 \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m                 \u001b[0mranking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margsort\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"def evaluate in main.py\"\"\"\n",
    "\n",
    "metrics = model.test_step(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92cdd8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671f6c66da9d4f3087e53db0f42e2d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504]]),\n",
       " [[11217, 143], [5673, 34], [4190, 62]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for negative_sample, queries, queries_unflatten, query_structures in tqdm(valid_dataloader, disable=not args.print_on_screen):\n",
    "    break\n",
    "    \n",
    "negative_sample, queries, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca9964",
   "metadata": {},
   "source": [
    "1. why is there no positive_sample in test_dataloader\n",
    "2. how to embed query vector and perform projection & intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daee4412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f9ce3bc63c4df6b2a5e12476a3893c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.13 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d5759c369871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;34m\"\"\"model.forward\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# negative_sample here is just a list of all entities, some of them are actually positive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_logit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idxs_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# ... scoring ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idxs_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'beta'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idxs_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0membed_query_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mforward_beta\u001b[1;34m(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegative_sample_regular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[0mnegative_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_regularizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative_sample_regular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 \u001b[0mnegative_logit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_logit_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[0mnegative_logit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mcal_logit_beta\u001b[1;34m(self, entity_embedding, query_dist)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mentity_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\distributions\\kl.py\u001b[0m in \u001b[0;36mkl_divergence\u001b[1;34m(p, q)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\distributions\\kl.py\u001b[0m in \u001b[0;36m_kl_beta_beta\u001b[1;34m(p, q)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_params_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_params_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mt3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[0mt4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcentration0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[0mt5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum_params_q\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_params_p\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_params_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.13 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\"\"\"model.test_step in models.py\"\"\"\n",
    "model, easy_answers, hard_answers, args, test_dataloader, query_name_dict = model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict\n",
    "\n",
    "model.eval()\n",
    "\n",
    "step = 0\n",
    "total_steps = len(test_dataloader)\n",
    "logs = collections.defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # process per batch\n",
    "    # loop through every validation dataset\n",
    "    # negative sample is basically all entities in nentity\n",
    "    for negative_sample, queries, queries_unflatten, query_structures in tqdm(test_dataloader, disable=not args.print_on_screen):\n",
    "        batch_queries_dict = collections.defaultdict(list)\n",
    "        batch_idxs_dict = collections.defaultdict(list)\n",
    "        \n",
    "        # for each test query\n",
    "        for i, query in enumerate(queries):\n",
    "            batch_queries_dict[query_structures[i]].append(query)\n",
    "            batch_idxs_dict[query_structures[i]].append(i)\n",
    "            \n",
    "        # convert each positive query to a LongTensor\n",
    "        for query_structure in batch_queries_dict:\n",
    "            if args.cuda:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "            else:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\n",
    "            \n",
    "        # convert each negative query to a LongTensor\n",
    "        if args.cuda:\n",
    "            negative_sample = negative_sample.cuda()\n",
    "            \n",
    "        # get prediction output\n",
    "        # (2, number_of_edges) same dimension with negative_sample\n",
    "        # this is basically embedding lookup\n",
    "        \"\"\"model.forward\"\"\"\n",
    "        # negative_sample here is just a list of all entities, some of them are actually positive\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "          \n",
    "        # ... scoring ...\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        # sort from maximum value based on logit values\n",
    "        argsort = torch.argsort(negative_logit, dim=1, descending=True)\n",
    "        ranking = argsort.clone().to(torch.float)\n",
    "        if len(argsort) == args.test_batch_size: # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "        else: # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args.cuda:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1).cuda()) # achieve the ranking of all entities\n",
    "            else:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1)) # achieve the ranking of all entities\n",
    "        \n",
    "        # loop through ranking\n",
    "        # score every query in the dataloader batch\n",
    "        for idx, (i, query, query_structure) in enumerate(zip(argsort[:, 0], queries_unflatten, query_structures)):\n",
    "            # get groundtruth labels\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = len(hard_answer)\n",
    "            num_easy = len(easy_answer)\n",
    "            assert len(hard_answer.intersection(easy_answer)) == 0\n",
    "\n",
    "            # compare ranking of groundtruth (easy_answer, hard_answer) and predicted results\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = torch.sort(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args.cuda:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float).cuda()\n",
    "            else:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float)\n",
    "            cur_ranking = cur_ranking - answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = torch.mean(1./cur_ranking).item()\n",
    "            h1 = torch.mean((cur_ranking <= 1).to(torch.float)).item()\n",
    "            h3 = torch.mean((cur_ranking <= 3).to(torch.float)).item()\n",
    "            h10 = torch.mean((cur_ranking <= 10).to(torch.float)).item()\n",
    "\n",
    "            logs[query_structure].append({\n",
    "                'MRR': mrr,\n",
    "                'HITS1': h1,\n",
    "                'HITS3': h3,\n",
    "                'HITS10': h10,\n",
    "                'num_hard_answer': num_hard,\n",
    "            })\n",
    "\n",
    "metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "for query_structure in logs:\n",
    "    for metric in logs[query_structure][0].keys():\n",
    "        if metric in ['num_hard_answer']:\n",
    "            continue\n",
    "        metrics[query_structure][metric] = sum([log[metric] for log in logs[query_structure]])/len(logs[query_structure])\n",
    "    metrics[query_structure]['num_queries'] = len(logs[query_structure])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d33e6df",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.14 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5c039bc54806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegative_sample_regular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         negative_embedding = model.entity_regularizer(\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative_sample_regular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m         \u001b[0mnegative_logit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_logit_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.14 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\"\"\"model.forward\"\"\"\n",
    "# model.forward(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "\n",
    "# model.geo == \"beta\"\n",
    "\n",
    "# done per batch\n",
    "\"\"\"model.forward_beta\"\"\"\n",
    "# compared to vec, just add union of offset embeddings\n",
    "\n",
    "# model.forward_beta(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "# negative_sample is a list of entities to be scored as potential answers to the queries\n",
    "# batch_queries_dict stores list of queries (in this case (e, r) to be scored)\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict = None, negative_sample, None, batch_queries_dict, batch_idxs_dict\n",
    "\n",
    "all_idxs, all_alpha_embeddings, all_beta_embeddings = [], [], []\n",
    "all_union_idxs, all_union_alpha_embeddings, all_union_beta_embeddings = [], [], []\n",
    "for query_structure in batch_queries_dict:\n",
    "    if 'u' in model.query_name_dict[query_structure] and 'DNF' in model.query_name_dict[query_structure]:\n",
    "        # embedding \n",
    "        alpha_embedding, beta_embedding, _ = model.embed_query_beta(model.transform_union_query(batch_queries_dict[query_structure], \n",
    "                                                            query_structure), \n",
    "                                                        model.transform_union_structure(query_structure), 0)\n",
    "        all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "        all_union_alpha_embeddings.append(alpha_embedding)\n",
    "        all_union_beta_embeddings.append(beta_embedding)\n",
    "    else:\n",
    "        alpha_embedding, beta_embedding, _ = model.embed_query_beta(batch_queries_dict[query_structure], query_structure, 0)\n",
    "        all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "        all_alpha_embeddings.append(alpha_embedding)\n",
    "        all_beta_embeddings.append(beta_embedding)\n",
    "\n",
    "if len(all_alpha_embeddings) > 0:\n",
    "    all_alpha_embeddings = torch.cat(all_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "    all_beta_embeddings = torch.cat(all_beta_embeddings, dim=0).unsqueeze(1)\n",
    "    all_dists = torch.distributions.beta.Beta(all_alpha_embeddings, all_beta_embeddings)\n",
    "if len(all_union_alpha_embeddings) > 0:\n",
    "    all_union_alpha_embeddings = torch.cat(all_union_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_beta_embeddings = torch.cat(all_union_beta_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "    all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "    all_union_dists = torch.distributions.beta.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "\n",
    "if type(subsampling_weight) != type(None):\n",
    "    subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "\n",
    "# in test, positive samples are not given\n",
    "if type(positive_sample) != type(None):\n",
    "    if len(all_alpha_embeddings) > 0:\n",
    "        positive_sample_regular = positive_sample[all_idxs]\n",
    "        positive_embedding = torch.index_select(model.entity_embedding, dim=0, index=positive_sample_regular).unsqueeze(1)\n",
    "        positive_logit = model.cal_logit_beta(positive_embedding, all_dists)\n",
    "    else:\n",
    "        positive_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0:\n",
    "        positive_sample_union = positive_sample[all_union_idxs]\n",
    "        positive_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=positive_sample_union).unsqueeze(1).unsqueeze(1)\n",
    "        )\n",
    "        positive_union_logit = model.cal_logit_beta(positive_embedding, all_union_dists)\n",
    "        positive_union_logit = torch.max(positive_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        positive_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "    positive_logit = torch.cat([positive_logit, positive_union_logit], dim=0)\n",
    "else:\n",
    "    positive_logit = None\n",
    "\n",
    "# in test, negative samples are basically all possible list of entities\n",
    "if type(negative_sample) != type(None):\n",
    "    if len(all_alpha_embeddings) > 0:\n",
    "        negative_sample_regular = negative_sample[all_idxs]\n",
    "        batch_size, negative_size = negative_sample_regular.shape\n",
    "        negative_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1)\n",
    "        )\n",
    "        negative_logit = model.cal_logit_beta(negative_embedding, all_dists)\n",
    "    else:\n",
    "        negative_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0:\n",
    "        negative_sample_union = negative_sample[all_union_idxs]\n",
    "        batch_size, negative_size = negative_sample_union.shape\n",
    "        negative_embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=negative_sample_union.view(-1)).view(batch_size, 1, negative_size, -1)\n",
    "        )\n",
    "        negative_union_logit = model.cal_logit_beta(negative_embedding, all_union_dists)\n",
    "        negative_union_logit = torch.max(negative_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        negative_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "    negative_logit = torch.cat([negative_logit, negative_union_logit], dim=0)\n",
    "else:\n",
    "    negative_logit = None\n",
    "\n",
    "positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d50b670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0719, 0.8787, 1.0673,  ..., 0.5811, 0.9096, 1.0109],\n",
       "         [1.0507, 0.8655, 1.0832,  ..., 0.5865, 0.9020, 1.0213],\n",
       "         [1.0689, 0.8797, 1.0773,  ..., 0.5793, 0.9014, 1.0295]],\n",
       "        device='cuda:0', grad_fn=<SplitBackward>),\n",
       " tensor([[1.2136, 1.1991, 0.6736,  ..., 1.0227, 1.1210, 1.2212],\n",
       "         [1.2104, 1.1918, 0.6813,  ..., 1.0259, 1.1246, 1.2350],\n",
       "         [1.2003, 1.1962, 0.6812,  ..., 1.0304, 1.1322, 1.2281]],\n",
       "        device='cuda:0', grad_fn=<SplitBackward>),\n",
       " 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.embed_query_beta in models.py\"\"\"\n",
    "# get the query embedding\n",
    "# input is (batch_size, query_type_length=2), query_structure=(e, r)\n",
    "# model.embed_query_beta(batch_queries_dict[query_structure], query_structure, 0)\n",
    "\n",
    "queries, query_structure, idx = batch_queries_dict[query_structure], query_structure, 0\n",
    "\n",
    "all_relation_flag = True\n",
    "for ele in query_structure[-1]:\n",
    "    if ele not in ['r', 'n']:\n",
    "        all_relation_flag = False\n",
    "        break\n",
    "if all_relation_flag:\n",
    "    # if anchor\n",
    "    if query_structure[0] == \"e\":\n",
    "        # get entity embedding\n",
    "        embedding = model.entity_regularizer(\n",
    "            torch.index_select(model.entity_embedding, dim=0, index=queries[:, idx])\n",
    "        )\n",
    "        idx += 1\n",
    "    else:\n",
    "        # recursion\n",
    "        alpha_embedding, beta_embedding, idx = model.embed_query_beta(queries, query_structure[0], idx)\n",
    "    for i in range(len(query_structure[-1])):\n",
    "        if query_structure[-1][i] == \"n\":\n",
    "            assert (queries[:, idx] == -2).all()\n",
    "            embedding = 1./embedding\n",
    "        else:\n",
    "            # get relation embedding\n",
    "            r_embedding = torch.index_select(model.relation_embedding, dim=0, index=queries[:, idx])\n",
    "            # add entity and relation embedding\n",
    "            embedding = model.projection_net(embedding, r_embedding)\n",
    "        idx += 1\n",
    "    alpha_embedding, beta_embedding = torch.chunk(embedding, 2, dim=-1)\n",
    "else:\n",
    "    alpha_embedding_list = []\n",
    "    beta_embedding_list = []\n",
    "    for i in range(len(query_structure)):\n",
    "        alpha_embedding, beta_embedding, idx = model.embed_query_beta(queries, query_structure[i], idx)\n",
    "        alpha_embedding_list.append(alpha_embedding)\n",
    "        beta_embedding_list.append(beta_embedding)\n",
    "    alpha_embedding, beta_embedding = model.center_net(torch.stack(alpha_embedding_list), torch.stack(beta_embedding_list))\n",
    "    \n",
    "alpha_embedding, beta_embedding, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3f38292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 500]), torch.Size([3, 500]), torch.Size([3, 1000]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_embedding.shape, beta_embedding.shape, embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22f2f4b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.14 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d6eacb1e9a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" model.cal_logit_beta \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_logit_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_dists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# score / calculate distance between candidate embedding and query embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# negative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mcal_logit_beta\u001b[1;34m(self, entity_embedding, query_dist)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcal_logit_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mentity_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\distributions\\beta.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, concentration1, concentration0, validate_args)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mconcentration1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcentration0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mconcentration1_concentration0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirichlet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDirichlet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcentration1_concentration0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirichlet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 4.00 GiB total capacity; 2.11 GiB already allocated; 0 bytes free; 2.14 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\"\"\" model.cal_logit_beta \"\"\"\n",
    "model.cal_logit_beta(negative_embedding, all_dists)\n",
    "\n",
    "# score / calculate distance between candidate embedding and query embedding\n",
    "# negative \n",
    "print(negative_embedding.shape, all_dists)\n",
    "\n",
    "entity_embedding, query_dist = negative_embedding, all_dists\n",
    "\n",
    "alpha_embedding, beta_embedding = torch.chunk(entity_embedding, 2, dim=-1)\n",
    "entity_dist = torch.distributions.beta.Beta(alpha_embedding, beta_embedding)\n",
    "logit = model.gamma - torch.norm(torch.distributions.kl.kl_divergence(entity_dist, query_dist), p=1, dim=-1)\n",
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771291e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b9bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "343fdc80cc68c688baad9e163e1f88e33cc019c87aed1c9258d7ce7a9f5d5e41"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
