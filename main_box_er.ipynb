{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67ebddc-92f9-4079-9bdf-03c1723da7bb",
   "metadata": {},
   "source": [
    "based on main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059f0ad7-07ad-40dd-9b51-13932b20d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from models import KGReasoning\n",
    "from dataloader import TestDataset, TrainDataset, SingledirectionalOneShotIterator\n",
    "# from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from util import flatten_query, list2tuple, parse_time, set_global_seed, eval_tuple\n",
    "\n",
    "import collections\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c30dcc-67a9-4c6c-95f8-12ba228079fe",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810639e0-395c-425b-9061-c767d7af1772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "query_name_dict = {('e',('r',)): '1p', \n",
    "                    ('e', ('r', 'r')): '2p',\n",
    "                    ('e', ('r', 'r', 'r')): '3p',\n",
    "                    (('e', ('r',)), ('e', ('r',))): '2i',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r',))): '3i',\n",
    "                    ((('e', ('r',)), ('e', ('r',))), ('r',)): 'ip',\n",
    "                    (('e', ('r', 'r')), ('e', ('r',))): 'pi',\n",
    "                    (('e', ('r',)), ('e', ('r', 'n'))): '2in',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('e', ('r', 'n'))): '3in',\n",
    "                    ((('e', ('r',)), ('e', ('r', 'n'))), ('r',)): 'inp',\n",
    "                    (('e', ('r', 'r')), ('e', ('r', 'n'))): 'pin',\n",
    "                    (('e', ('r', 'r', 'n')), ('e', ('r',))): 'pni',\n",
    "                    (('e', ('r',)), ('e', ('r',)), ('u',)): '2u-DNF',\n",
    "                    ((('e', ('r',)), ('e', ('r',)), ('u',)), ('r',)): 'up-DNF',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n',)): '2u-DM',\n",
    "                    ((('e', ('r', 'n')), ('e', ('r', 'n'))), ('n', 'r')): 'up-DM'\n",
    "                }\n",
    "name_query_dict = {value: key for key, value in query_name_dict.items()}\n",
    "all_tasks = list(name_query_dict.keys()) # ['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', '2u-DM', 'up-DNF', 'up-DM']\n",
    "\n",
    "print(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bcf015-3999-443a-8b67-de3a03662b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyArgs:\n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "args = DummyArgs()\n",
    "args.cuda = True\n",
    "args.geo = \"box\" # choices=['vec', 'box', 'beta']\n",
    "args.gamma = 12.0\n",
    "args.box_mode = \"(none,0.02)\" # Query2box\n",
    "args.beta_mode = \"(1600,2)\" # BetaE relational projection\n",
    "args.data_path = \"data/FB15k-237-betae\"\n",
    "args.batch_size = 64 #1024\n",
    "args.cpu_num = 1# 10\n",
    "args.negative_sample_size = 128\n",
    "args.hidden_dim = 500\n",
    "args.test_batch_size = 3 #2\n",
    "args.print_on_screen = True\n",
    "args.test_log_steps = 1000\n",
    "args.learning_rate = 0.0001\n",
    "args.max_steps = 100000\n",
    "args.evaluate_union = \"DNF\" # choices=['DNF', 'DM'] evaluate union querioes, disjunctive normal form (DNF) or de Morgan's laws (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de24b73d-f941-433b-b85c-646c87df325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1p', '2p', '3p', '2i', '3i', 'ip', 'pi', '2in', '3in', 'inp', 'pin', 'pni', '2u-DNF', 'up-DNF', '2u-DM', 'up-DM']\n"
     ]
    }
   ],
   "source": [
    "# different query types\n",
    "tasks = all_tasks[0:1]\n",
    "\n",
    "if args.geo in ['box']:\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.box_mode)\n",
    "elif args.geo in ['vec']:\n",
    "    tmp_str = \"g-{}\".format(args.gamma)\n",
    "elif args.geo == 'beta':\n",
    "    tmp_str = \"g-{}-mode-{}\".format(args.gamma, args.beta_mode)\n",
    "\n",
    "print(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925f09da-75e3-48a9-8aef-ce389cccac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/stats.txt' % args.data_path) as f:\n",
    "    entrel = f.readlines()\n",
    "    nentity = int(entrel[0].split(' ')[-1])\n",
    "    nrelation = int(entrel[1].split(' ')[-1])\n",
    "\n",
    "args.nentity = nentity\n",
    "args.nrelation = nrelation\n",
    "\n",
    "logging.info('-------------------------------'*3)\n",
    "logging.info('Geo: %s' % args.geo)\n",
    "logging.info('Data Path: %s' % args.data_path)\n",
    "logging.info('#entity: %d' % nentity)\n",
    "logging.info('#relation: %d' % nrelation)\n",
    "# logging.info('#max steps: %d' % args.max_steps)\n",
    "# logging.info('Evaluate unoins using: %s' % args.evaluate_union)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24a6e6-a9e3-4d88-8b9a-49b0bcb907de",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05285434-3f28-439c-9214-e835ecedf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args, tasks):\n",
    "    '''\n",
    "    Load queries and remove queries not in tasks\n",
    "    '''\n",
    "    logging.info(\"loading data\")\n",
    "    train_queries = pickle.load(open(os.path.join(args.data_path, \"train-queries.pkl\"), 'rb'))\n",
    "    train_answers = pickle.load(open(os.path.join(args.data_path, \"train-answers.pkl\"), 'rb'))\n",
    "    valid_queries = pickle.load(open(os.path.join(args.data_path, \"valid-queries.pkl\"), 'rb'))\n",
    "    valid_hard_answers = pickle.load(open(os.path.join(args.data_path, \"valid-hard-answers.pkl\"), 'rb'))\n",
    "    valid_easy_answers = pickle.load(open(os.path.join(args.data_path, \"valid-easy-answers.pkl\"), 'rb'))\n",
    "    test_queries = pickle.load(open(os.path.join(args.data_path, \"test-queries.pkl\"), 'rb'))\n",
    "    test_hard_answers = pickle.load(open(os.path.join(args.data_path, \"test-hard-answers.pkl\"), 'rb'))\n",
    "    test_easy_answers = pickle.load(open(os.path.join(args.data_path, \"test-easy-answers.pkl\"), 'rb'))\n",
    "    \n",
    "    # remove tasks not in args.tasks\n",
    "    for name in all_tasks:\n",
    "        if 'u' in name:\n",
    "            name, evaluate_union = name.split('-')\n",
    "        else:\n",
    "            evaluate_union = args.evaluate_union\n",
    "        if name not in tasks or evaluate_union != args.evaluate_union:\n",
    "            query_structure = name_query_dict[name if 'u' not in name else '-'.join([name, evaluate_union])]\n",
    "            if query_structure in train_queries:\n",
    "                del train_queries[query_structure]\n",
    "            if query_structure in valid_queries:\n",
    "                del valid_queries[query_structure]\n",
    "            if query_structure in test_queries:\n",
    "                del test_queries[query_structure]\n",
    "\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3d679e-4264-47ec-8530-9f8cc52b7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LOAD DATA\n",
    "based on tasks defined in args\n",
    "\"\"\"\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3c859-326a-44a7-9821-f48dda94e186",
   "metadata": {},
   "source": [
    "1. train_queries: for (e, r) given entityID and relationID, find all other entities that are connected to it.\n",
    "2. train_answers: given (e, r) this is the groundtruth answers of all entityIDs that are connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e36ea2b-54a6-49ff-8791-3a47cd98c06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(collections.defaultdict, 1),\n",
       " (collections.defaultdict, 1496890),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 95094),\n",
       " (collections.defaultdict, 1),\n",
       " (collections.defaultdict, 97804),\n",
       " (collections.defaultdict, 97804)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(type(x), len(x)) for x in [train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0989196-e3d2-43b3-aa73-b622426225e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "(6288, (8,))\n",
      "False\n",
      "valid_hard_answers set()\n",
      "valid_easy_answers set()\n",
      "**********\n",
      "(6288, (8,))\n",
      "True\n",
      "train_answers {9, 11, 117, 399}\n",
      "**********\n",
      "(6288, (8,))\n",
      "False\n",
      "test_hard_answers set()\n",
      "test_easy_answers set()\n"
     ]
    }
   ],
   "source": [
    "ex_val_q = (6288, (8,))\n",
    "print(\"*\" * 10)\n",
    "print(ex_val_q)\n",
    "print(ex_val_q in valid_queries[('e', ('r', ))])\n",
    "print(\"valid_hard_answers\", valid_hard_answers[ex_val_q])\n",
    "print(\"valid_easy_answers\", valid_easy_answers[ex_val_q])\n",
    "\n",
    "# get example query\n",
    "ex_q = ex_val_q #(6288, (8,))\n",
    "print(\"*\" * 10)\n",
    "print(ex_q)\n",
    "print(ex_q in train_queries[('e', ('r', ))])\n",
    "print(\"train_answers\", train_answers[ex_q])\n",
    "\n",
    "ex_test_q = ex_val_q\n",
    "print(\"*\" * 10)\n",
    "print(ex_test_q)\n",
    "print(ex_test_q in test_queries[('e', ('r', ))])\n",
    "print(\"test_hard_answers\", test_hard_answers[ex_val_q])\n",
    "print(\"test_easy_answers\", test_easy_answers[ex_val_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361141a3-9026-43e9-b95e-c20f65b11a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train_queries 149689\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAINING Data Preparation\n",
    "\"\"\"\n",
    "train_path_queries = defaultdict(set)\n",
    "for query_structure in train_queries:\n",
    "#     train_path_queries[query_structure] = set(random.sample(train_queries[query_structure], 1))\n",
    "    train_path_queries[query_structure] = train_queries[query_structure]\n",
    "            \n",
    "train_path_queries = flatten_query(train_path_queries)\n",
    "print(\"number of train_queries\", len(train_path_queries))\n",
    "train_path_iterator = SingledirectionalOneShotIterator(DataLoader(\n",
    "                            # {(e,r): (entityID, relID)} and {(e, r): [entityID]}\n",
    "                            TrainDataset(train_path_queries, nentity, nrelation, args.negative_sample_size, train_answers),\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=args.cpu_num,\n",
    "                            collate_fn=TrainDataset.collate_fn\n",
    "                        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4f3a56-d4b9-4e3f-8610-42bd94e8c321",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error ('e', ('r',))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "VALIDATION Data Preparation\n",
    "\"\"\"\n",
    "# for each type of structure / key\n",
    "for query_structure in valid_queries:\n",
    "    try:\n",
    "        print(query_name_dict[query_structure[1]]+\": \"+str(len(valid_queries[query_structure])))\n",
    "    except:\n",
    "        print(\"error\", query_structure)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    TestDataset(\n",
    "        flatten_query(valid_queries), \n",
    "        args.nentity, \n",
    "        args.nrelation, \n",
    "    ), \n",
    "    batch_size=args.test_batch_size,\n",
    "    num_workers=args.cpu_num, \n",
    "    collate_fn=TestDataset.collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcc71dd-c692-4b5f-bcb2-4e15fbb8ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter gamma: torch.Size([1]), require_grad = False\n",
      "Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "Parameter entity_embedding: torch.Size([14505, 500]), require_grad = True\n",
      "Parameter relation_embedding: torch.Size([474, 500]), require_grad = True\n",
      "Parameter offset_embedding: torch.Size([474, 500]), require_grad = True\n",
      "Parameter center_net.layer1.weight: torch.Size([500, 500]), require_grad = True\n",
      "Parameter center_net.layer1.bias: torch.Size([500]), require_grad = True\n",
      "Parameter center_net.layer2.weight: torch.Size([500, 500]), require_grad = True\n",
      "Parameter center_net.layer2.bias: torch.Size([500]), require_grad = True\n",
      "Parameter offset_net.layer1.weight: torch.Size([500, 500]), require_grad = True\n",
      "Parameter offset_net.layer1.bias: torch.Size([500]), require_grad = True\n",
      "Parameter offset_net.layer2.weight: torch.Size([500, 500]), require_grad = True\n",
      "Parameter offset_net.layer2.bias: torch.Size([500]), require_grad = True\n",
      "Parameter Number: 8728500\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL DEFINITION\n",
    "\"\"\"\n",
    "model = KGReasoning(\n",
    "    nentity=nentity,\n",
    "    nrelation=nrelation,\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    gamma=args.gamma,\n",
    "    geo=args.geo,\n",
    "    use_cuda = args.cuda,\n",
    "    box_mode=eval_tuple(args.box_mode),\n",
    "    beta_mode = eval_tuple(args.beta_mode),\n",
    "    test_batch_size=args.test_batch_size,\n",
    "    query_name_dict = query_name_dict\n",
    ")\n",
    "\n",
    "logging.info('Model Parameter Configuration:')\n",
    "num_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "    if param.requires_grad:\n",
    "        num_params += np.prod(param.size())\n",
    "print('Parameter Number: %d' % num_params)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "current_learning_rate = args.learning_rate\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=current_learning_rate\n",
    ")\n",
    "warm_up_steps = args.max_steps // 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0855a87-dd99-4832-b2fb-3eb8519ab0bd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bfcdb2-a2c2-49fc-a329-f80a198a60c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8343fe35f32b4c43af77a4b47b0755a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-195ec1d49a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# train model for a step over all batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_path_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtraining_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, optimizer, train_iterator, args, step)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mpositive_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsampling_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_queries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_structures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mbatch_queries_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mbatch_idxs_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\KGReasoning\\dataloader.py\u001b[0m in \u001b[0;36mone_shot_iterator\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_shot_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\my-rdkit-env\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAIN LOOP\n",
    "\"\"\"\n",
    "init_step = 0\n",
    "\n",
    "training_logs = []\n",
    "# loop over all batches\n",
    "# initialising train_path_iterator is expensive. So at certain loop it might take some time to load\n",
    "for step in tqdm(range(init_step, args.max_steps)):\n",
    "    # train model for a step over all batches\n",
    "    log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "    training_logs.append(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25b30b6e-05ce-4343-b36f-a8e6ca97332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(\n",
    "    {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    },\n",
    "    os.path.join(\"checkpoint\", \"model-box-er.pt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2873f-ca65-406b-91c6-a9d1059a20c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c781f49-e149-4cd2-846b-6f7aca456631",
   "metadata": {},
   "source": [
    "## DEBUG TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d748f69-474b-47e9-ade8-07655dd285dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_sample_loss': 0.39944127202033997,\n",
       " 'negative_sample_loss': 1.0847606658935547,\n",
       " 'loss': 0.7421009540557861}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\n",
    "\n",
    "# model.train_step(model, optimizer, train_other_iterator, args, step)\n",
    "\n",
    "model, optimizer, train_iterator, args, step = model, optimizer, train_path_iterator, args, step\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# there's an overhead operation to shufflte the train_iterator that makes this expensive to run\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\n",
    "\n",
    "# group queries into batch\n",
    "batch_queries_dict = collections.defaultdict(list)\n",
    "batch_idxs_dict = collections.defaultdict(list)\n",
    "for i, query in enumerate(batch_queries): # group queries with same structure\n",
    "    batch_queries_dict[query_structures[i]].append(query)\n",
    "    batch_idxs_dict[query_structures[i]].append(i)\n",
    "\n",
    "for query_structure in batch_queries_dict:\n",
    "    if args.cuda:\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "    else:\n",
    "        batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\n",
    "\n",
    "if args.cuda:\n",
    "    positive_sample = positive_sample.cuda()\n",
    "    negative_sample = negative_sample.cuda()\n",
    "    subsampling_weight = subsampling_weight.cuda()\n",
    "\n",
    "# score positive and negative samples\n",
    "positive_logit, negative_logit, subsampling_weight, _ = model(positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "\n",
    "# calculate loss\n",
    "# positive samples should have label of 1 while negative samples label of 0\n",
    "negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\n",
    "positive_score = F.logsigmoid(positive_logit).mean(dim=1)\n",
    "# aggregate loss with subsampling_weight\n",
    "positive_sample_loss = - (subsampling_weight * positive_score).sum()\n",
    "negative_sample_loss = - (subsampling_weight * negative_score).sum()\n",
    "positive_sample_loss /= subsampling_weight.sum()\n",
    "negative_sample_loss /= subsampling_weight.sum()\n",
    "loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "log = {\n",
    "    'positive_sample_loss': positive_sample_loss.item(),\n",
    "    'negative_sample_loss': negative_sample_loss.item(),\n",
    "    'loss': loss.item(),\n",
    "}\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be0565a-6810-4e7b-87cc-34a456006c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== input ===\n",
      "torch.Size([64]) torch.Size([64, 128]) 64 64 torch.Size([64])\n",
      "=== output ===\n",
      "torch.Size([64, 1]) torch.Size([64, 128])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== input ===\")\n",
    "print(positive_sample.shape, negative_sample.shape, len(batch_queries), len(query_structures), subsampling_weight.shape)\n",
    "print(\"=== output ===\")\n",
    "print(positive_logit.shape, negative_logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0021b4a-3f5e-45a4-8fb2-577fed266eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2061813a-7d68-4213-9c0f-e03a82497261",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd87bedf-3738-4190-a7d6-fe2148b4db3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "checkpoint = torch.load(os.path.join(\"checkpoint\", \"model.pt\"))\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0330becc-417c-4054-b067-aae8b2c6cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step):\n",
    "    '''\n",
    "    Evaluate queries in dataloader\n",
    "    '''\n",
    "    average_metrics = defaultdict(float)\n",
    "    all_metrics = defaultdict(float)\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics:\n",
    "        log_metrics(mode+\" \"+query_name_dict[query_structure], step, metrics[query_structure])\n",
    "        for metric in metrics[query_structure]:\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != 'num_queries':\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "        num_queries += metrics[query_structure]['num_queries']\n",
    "        num_query_structures += 1\n",
    "\n",
    "    for metric in average_metrics:\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    log_metrics('%s average'%mode, step, average_metrics)\n",
    "\n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9becd1-6d16-4448-bc03-302d2c28bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(mode, step, metrics):\n",
    "    '''\n",
    "    Print the evaluation logs\n",
    "    '''\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e329dce-199c-4ece-b3fd-a6801dd6e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44921785-a04a-4497-881f-f7ce14045c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"`\n",
    "EVAL\n",
    "\"\"\"\n",
    "step = -1\n",
    "valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict, 'Valid', step)\n",
    "valid_all_metrics\n",
    "\n",
    "# after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562e202-6d27-4191-aa22-5f294bc66016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9ace12-0564-4b65-bab9-43d42ffa01c8",
   "metadata": {},
   "source": [
    "## DEBUG TEST STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4ffd7b-d3e9-4af7-97f3-22e8504f32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6698/6698 [02:03<00:00, 54.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function models.KGReasoning.test_step.<locals>.<lambda>()>,\n",
       "            {('e', ('r',)): defaultdict(int,\n",
       "                         {'MRR': 0.009632772394135068,\n",
       "                          'HITS1': 0.008909909141400957,\n",
       "                          'HITS3': 0.00903797208566882,\n",
       "                          'HITS10': 0.009823186617451034,\n",
       "                          'num_queries': 20094})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def evaluate in main.py\"\"\"\n",
    "\n",
    "metrics = model.test_step(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c530c00-d2da-4e8f-b2b7-7a036e1639e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0790d45b52ec4e57820e0dc979625c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "         [    0,     1,     2,  ..., 14502, 14503, 14504]]),\n",
       " [[11217, 143], [5673, 34], [4190, 62]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for negative_sample, queries, queries_unflatten, query_structures in tqdm(valid_dataloader, disable=not args.print_on_screen):\n",
    "    break\n",
    "    \n",
    "negative_sample, queries, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9d867-2cf2-4ef9-8bda-2e42a52292ec",
   "metadata": {},
   "source": [
    "1. why is there no positive_sample in test_dataloader\n",
    "2. how to embed query vector and perform projection & intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451ddc29-be51-4803-8b75-5ceaa2fe10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "        [    0,     1,     2,  ..., 14502, 14503, 14504],\n",
       "        [    0,     1,     2,  ..., 14502, 14503, 14504]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "087e015d-4567-45a2-9e05-1ad756270268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32751d7568a470dbbc9a1d898ca9a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {('e', ('r',)): defaultdict(int,\n",
       "                         {'MRR': 0.009632772394135068,\n",
       "                          'HITS1': 0.008909909141400957,\n",
       "                          'HITS3': 0.00903797208566882,\n",
       "                          'HITS10': 0.009823186617451034,\n",
       "                          'num_queries': 20094})})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.test_step in models.py\"\"\"\n",
    "model, easy_answers, hard_answers, args, test_dataloader, query_name_dict = model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict\n",
    "\n",
    "model.eval()\n",
    "\n",
    "step = 0\n",
    "total_steps = len(test_dataloader)\n",
    "logs = collections.defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # process per batch\n",
    "    # loop through every validation dataset\n",
    "    # negative sample is basically all entities in nentity\n",
    "    for negative_sample, queries, queries_unflatten, query_structures in tqdm(test_dataloader, disable=not args.print_on_screen):\n",
    "        batch_queries_dict = collections.defaultdict(list)\n",
    "        batch_idxs_dict = collections.defaultdict(list)\n",
    "        \n",
    "        # for each test query\n",
    "        for i, query in enumerate(queries):\n",
    "            batch_queries_dict[query_structures[i]].append(query)\n",
    "            batch_idxs_dict[query_structures[i]].append(i)\n",
    "            \n",
    "        # convert each positive query to a LongTensor\n",
    "        for query_structure in batch_queries_dict:\n",
    "            if args.cuda:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure]).cuda()\n",
    "            else:\n",
    "                batch_queries_dict[query_structure] = torch.LongTensor(batch_queries_dict[query_structure])\n",
    "            \n",
    "        # convert each negative query to a LongTensor\n",
    "        if args.cuda:\n",
    "            negative_sample = negative_sample.cuda()\n",
    "            \n",
    "        # get prediction output\n",
    "        # (2, number_of_edges) same dimension with negative_sample\n",
    "        # this is basically embedding lookup\n",
    "        \"\"\"model.forward\"\"\"\n",
    "        # negative_sample here is just a list of all entities, some of them are actually positive\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "          \n",
    "        # ... scoring ...\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        # sort from maximum value based on logit values\n",
    "        argsort = torch.argsort(negative_logit, dim=1, descending=True)\n",
    "        ranking = argsort.clone().to(torch.float)\n",
    "        if len(argsort) == args.test_batch_size: # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "        else: # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args.cuda:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1).cuda()) # achieve the ranking of all entities\n",
    "            else:\n",
    "                ranking = ranking.scatter_(1, argsort, torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], 1)) # achieve the ranking of all entities\n",
    "        \n",
    "        # loop through ranking\n",
    "        # score every query in the dataloader batch\n",
    "        for idx, (i, query, query_structure) in enumerate(zip(argsort[:, 0], queries_unflatten, query_structures)):\n",
    "            # get groundtruth labels\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = len(hard_answer)\n",
    "            num_easy = len(easy_answer)\n",
    "            assert len(hard_answer.intersection(easy_answer)) == 0\n",
    "\n",
    "            # compare ranking of groundtruth (easy_answer, hard_answer) and predicted results\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = torch.sort(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args.cuda:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float).cuda()\n",
    "            else:\n",
    "                answer_list = torch.arange(num_hard + num_easy).to(torch.float)\n",
    "            cur_ranking = cur_ranking - answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = torch.mean(1./cur_ranking).item()\n",
    "            h1 = torch.mean((cur_ranking <= 1).to(torch.float)).item()\n",
    "            h3 = torch.mean((cur_ranking <= 3).to(torch.float)).item()\n",
    "            h10 = torch.mean((cur_ranking <= 10).to(torch.float)).item()\n",
    "\n",
    "            logs[query_structure].append({\n",
    "                'MRR': mrr,\n",
    "                'HITS1': h1,\n",
    "                'HITS3': h3,\n",
    "                'HITS10': h10,\n",
    "                'num_hard_answer': num_hard,\n",
    "            })\n",
    "\n",
    "metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "for query_structure in logs:\n",
    "    for metric in logs[query_structure][0].keys():\n",
    "        if metric in ['num_hard_answer']:\n",
    "            continue\n",
    "        metrics[query_structure][metric] = sum([log[metric] for log in logs[query_structure]])/len(logs[query_structure])\n",
    "    metrics[query_structure]['num_queries'] = len(logs[query_structure])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c44708ce-8b20-4c84-b2d2-3725ce2298d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([[6.2495, 6.0508, 6.2885,  ..., 6.2162, 6.1718, 5.5565],\n",
       "         [5.2960, 5.4308, 5.9617,  ..., 5.8868, 5.7818, 5.8520],\n",
       "         [5.7562, 5.4614, 6.0019,  ..., 5.8199, 5.7874, 5.8295]],\n",
       "        device='cuda:0', grad_fn=<CatBackward>),\n",
       " None,\n",
       " [0, 1, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.forward\"\"\"\n",
    "# model.forward(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "\n",
    "# model.geo == \"box\"\n",
    "\n",
    "# done per batch\n",
    "\"\"\"model.forward_box\"\"\"\n",
    "# compared to vec, just add union of offset embeddings\n",
    "\n",
    "# model.forward_box(self, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "# negative_sample is a list of entities to be scored as potential answers to the queries\n",
    "# batch_queries_dict stores list of queries (in this case (e, r) to be scored)\n",
    "positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict = None, negative_sample, None, batch_queries_dict, batch_idxs_dict\n",
    "\n",
    "all_center_embeddings, all_offset_embeddings, all_idxs = [], [], []\n",
    "all_union_center_embeddings, all_union_offset_embeddings, all_union_idxs = [], [], []\n",
    "for query_structure in batch_queries_dict:\n",
    "    if 'u' in model.query_name_dict[query_structure]:\n",
    "        # embedding \n",
    "        center_embedding, offset_embedding, _ = model.embed_query_vbox(model.transform_union_query(batch_queries_dict[query_structure], \n",
    "                                                            query_structure), \n",
    "                                                        model.transform_union_structure(query_structure), 0)\n",
    "        all_union_center_embeddings.append(center_embedding)\n",
    "        all_union_offset_embeddings.append(offset_embedding)\n",
    "        all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "    else:\n",
    "        # get vector embedding for each query (anchor + projection + intersection)\n",
    "        # this will be compared with the groundtruth answer entity embedding\n",
    "        center_embedding, offset_embedding, _ = model.embed_query_box(batch_queries_dict[query_structure], query_structure, 0)\n",
    "        all_center_embeddings.append(center_embedding)\n",
    "        all_offset_embeddings.append(offset_embedding)\n",
    "        all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "\n",
    "if len(all_center_embeddings) > 0 and len(all_offset_embeddings) > 0:\n",
    "    all_center_embeddings = torch.cat(all_center_embeddings, dim=0).unsqueeze(1)\n",
    "    all_offset_embeddings = torch.cat(all_offset_embeddings, dim=0).unsqueeze(1)\n",
    "if len(all_union_center_embeddings) > 0 and len(all_union_offset_embeddings) > 0:\n",
    "    all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_offset_embeddings = torch.cat(all_union_offset_embeddings, dim=0).unsqueeze(1)\n",
    "    all_union_center_embeddings = all_union_center_embeddings.view(all_union_center_embeddings.shape[0]//2, 2, 1, -1)\n",
    "    all_union_offset_embeddings = all_union_offset_embeddings.view(all_union_offset_embeddings.shape[0]//2, 2, 1, -1)\n",
    "\n",
    "if type(subsampling_weight) != type(None):\n",
    "    subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "\n",
    "# in test, positive samples are not given\n",
    "if type(positive_sample) != type(None):\n",
    "    if len(all_center_embeddings) > 0:\n",
    "        positive_sample_regular = positive_sample[all_idxs]\n",
    "        positive_embedding = torch.index_select(model.entity_embedding, dim=0, index=positive_sample_regular).unsqueeze(1)\n",
    "        positive_logit = model.cal_logit_box(positive_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "    else:\n",
    "        positive_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_center_embeddings) > 0:\n",
    "        positive_sample_union = positive_sample[all_union_idxs]\n",
    "        positive_embedding = torch.index_select(model.entity_embedding, dim=0, index=positive_sample_union).unsqueeze(1).unsqueeze(1)\n",
    "        positive_union_logit = model.cal_logit_box(positive_embedding, all_union_center_embeddings, all_offset_embeddings)\n",
    "        positive_union_logit = torch.max(positive_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        positive_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "    positive_logit = torch.cat([positive_logit, positive_union_logit], dim=0)\n",
    "else:\n",
    "    positive_logit = None\n",
    "\n",
    "# in test, negative samples are basically all possible list of entities\n",
    "if type(negative_sample) != type(None):\n",
    "    if len(all_center_embeddings) > 0:\n",
    "        negative_sample_regular = negative_sample[all_idxs]\n",
    "        batch_size, negative_size = negative_sample_regular.shape\n",
    "        negative_embedding = torch.index_select(model.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1)\n",
    "        negative_logit = model.cal_logit_box(negative_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "    else:\n",
    "        negative_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "\n",
    "    if len(all_union_center_embeddings) > 0:\n",
    "        negative_sample_union = negative_sample[all_union_idxs]\n",
    "        batch_size, negative_size = negative_sample_union.shape\n",
    "        negative_embedding = torch.index_select(model.entity_embedding, dim=0, index=negative_sample_union.view(-1)).view(batch_size, 1, negative_size, -1)\n",
    "        negative_union_logit = model.cal_logit_(neboxgative_embedding, all_union_center_embeddings, all_offset_embeddings)\n",
    "        negative_union_logit = torch.max(negative_union_logit, dim=1)[0]\n",
    "    else:\n",
    "        negative_union_logit = torch.Tensor([]).to(model.entity_embedding.device)\n",
    "    negative_logit = torch.cat([negative_logit, negative_union_logit], dim=0)\n",
    "else:\n",
    "    negative_logit = None\n",
    "\n",
    "positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cf7d8a-221f-4760-bf36-64f3f80db165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0481, -0.0327,  0.0139,  ...,  0.0114, -0.0135, -0.0339],\n",
       "         [ 0.0293, -0.0434, -0.0025,  ...,  0.0150,  0.0325,  0.0024],\n",
       "         [-0.0111, -0.0158, -0.0044,  ..., -0.0344,  0.0276, -0.0045]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[0.0392, 0.0410, 0.0311,  ..., 0.0323, 0.0458, 0.0522],\n",
       "         [0.0257, 0.0153, 0.0160,  ..., 0.0154, 0.0040, 0.0260],\n",
       "         [0.0090, 0.0043, 0.0554,  ..., 0.0342, 0.0494, 0.0101]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.embed_query_box in models.py\"\"\"\n",
    "# get the query embedding\n",
    "# input is (batch_size, query_type_length=2), query_structure=(e, r)\n",
    "# model.embed_query_vec(batch_queries_dict[query_structure], query_structure, 0)\n",
    "\n",
    "queries, query_structure, idx = batch_queries_dict[query_structure], query_structure, 0\n",
    "\n",
    "all_relation_flag = True\n",
    "for ele in query_structure[-1]:\n",
    "    if ele not in ['r', 'n']:\n",
    "        all_relation_flag = False\n",
    "        break\n",
    "if all_relation_flag:\n",
    "    # if anchor\n",
    "    if query_structure[0] == \"e\":\n",
    "        # get entity embedding\n",
    "        embedding = torch.index_select(model.entity_embedding, dim=0, index=queries[:, idx])\n",
    "        idx += 1\n",
    "    else:\n",
    "        # recursion\n",
    "        embedding, offset_embedding, idx = model.embed_query_box(queries, query_structure[0], idx)\n",
    "    for i in range(len(query_structure[-1])):\n",
    "        if query_structure[-1][i] == \"n\":\n",
    "            assert False, \"box cannot handle queries with negation\"\n",
    "        else:\n",
    "            # get relation embedding\n",
    "            r_embedding = torch.index_select(model.relation_embedding, dim=0, index=queries[:, idx])\n",
    "            # get offset embedding\n",
    "            r_offset_embedding = torch.index_select(model.offset_embedding, dim=0, index=queries[:, idx])\n",
    "            # add entity and relation embedding\n",
    "            embedding += r_embedding\n",
    "            offset_embedding += model.func(r_offset_embedding)\n",
    "        idx += 1\n",
    "else:\n",
    "    embedding_list = []\n",
    "    offset_embedding_list = []\n",
    "    for i in range(len(query_structure)):\n",
    "        embedding, offset_embedding, idx = model.embed_query_box(queries, query_structure[i], idx)\n",
    "        embedding_list.append(embedding)\n",
    "        offset_embedding_list.append(offset_embedding)\n",
    "    embedding = model.center_net(torch.stack(embedding_list))\n",
    "    offset_embedding = model.offset_net(torch.stack(offset_embedding_list))\n",
    "    \n",
    "embedding, offset_embedding, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d883d726-fc13-45da-ab3c-b4be25f68822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 14505, 500]) torch.Size([3, 1, 500]) torch.Size([3, 1, 500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 14505, 500]),\n",
       " torch.Size([3, 14505, 500]),\n",
       " torch.Size([3, 14505, 500]),\n",
       " torch.Size([3, 14505]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model.cal_logit_box \"\"\"\n",
    "# score / calculate distance between candidate embedding and query embedding\n",
    "# negative \n",
    "print(negative_embedding.shape, all_center_embeddings.shape, all_offset_embeddings.shape)\n",
    "\n",
    "entity_embedding, query_center_embedding, query_offset_embedding = negative_embedding, all_center_embeddings, all_offset_embeddings\n",
    "\n",
    "delta = (entity_embedding - query_center_embedding).abs()\n",
    "distance_out = F.relu(delta - query_offset_embedding)\n",
    "distance_in = torch.min(delta, query_offset_embedding)\n",
    "logit = model.gamma - torch.norm(distance_out, p=1, dim=-1) - model.cen * torch.norm(distance_in, p=1, dim=-1)\n",
    "\n",
    "delta.shape, distance_out.shape, distance_in.shape, logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98ec62-b9ef-4f56-82bd-3442c40df165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3edad-b6c0-4eb0-a172-60e0246945cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
